<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.33">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Online and Stochastic Gradient Descent</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../favicon.ico" rel="icon">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-ea385d0e468b0dd5ea5bf0780b1290d9.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-c5a5d5e27fcc88644031c24cff017230.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<link rel="shortcut icon" href="../favicon.ico">
<script id="MathJax-script" async="" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>


<!-- Google tag (gtag.js) -->
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-GZHXTPTRRE"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-GZHXTPTRRE');
</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Spring 2026</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="https://discord.gg/dES3fSPEeC"> 
<span class="menu-text">Discord</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://www.gradescope.com/courses/1233250"> 
<span class="menu-text">Gradescope</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../syllabus.html"> 
<span class="menu-text">Syllabus</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#online-learning" id="toc-online-learning" class="nav-link active" data-scroll-target="#online-learning">Online Learning</a></li>
  <li><a href="#online-gradient-descent" id="toc-online-gradient-descent" class="nav-link" data-scroll-target="#online-gradient-descent">Online Gradient Descent</a></li>
  <li><a href="#stochastic-gradient-descent" id="toc-stochastic-gradient-descent" class="nav-link" data-scroll-target="#stochastic-gradient-descent">Stochastic Gradient Descent</a></li>
  <li><a href="#preconditioning" id="toc-preconditioning" class="nav-link" data-scroll-target="#preconditioning">Preconditioning</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content column-page-left" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><strong>Online and Stochastic Gradient Descent</strong></h1>
</div>



<div class="quarto-title-meta column-page-left">

    
  
    
  </div>
  


</header>


<p>Recall the standard optimization setting. We are given a function <span class="math inline">\(f:\mathbb{R}^d \to \mathbb{R}\)</span> to minimize, a function oracle and a gradient oracle. The function oracle returns <span class="math inline">\(f(\mathbf{x})\)</span> and the gradient oracle returns <span class="math inline">\(\nabla f(\mathbf{x})\)</span> for any input <span class="math inline">\(\mathbf{x} \in \mathbb{R}^d\)</span>. The goal is to minimize the number of calls to the oracles to find an output <span class="math inline">\(\hat{\mathbf{x}}\)</span> such that <span class="math display">\[f(\hat{\mathbf{x}}) \leq \min_{\mathbf{x}} f(\mathbf{x}) + \epsilon\]</span> for <span class="math inline">\(\epsilon &gt; 0.\)</span></p>
<p>In machine learning applications, the function <span class="math inline">\(f\)</span> is typically a loss function defined for a particular training dataset. Today, we’ll discuss the online setting where the dataset changes over time. Examples of the online setting include:</p>
<ul>
<li><p>Spam filters that are incrementally updated as new types of spam emails are developed.</p></li>
<li><p>Text recommendation engines like Github Copilot that need to be updated as software libraries change.</p></li>
<li><p>Content recommendation systems that need to adapt to user behavior and clicks over time.</p></li>
<li><p>Image recognition systems such as iNaturalist that are updated with user expertise.</p></li>
</ul>
<section id="online-learning" class="level2">
<h2 class="anchored" data-anchor-id="online-learning">Online Learning</h2>
<p>Consider a model <span class="math inline">\(M_\mathbf{x}\)</span> parameterized by parameters <span class="math inline">\(\mathbf{x}\)</span>. We want to find good parameters to minimize a loss function <span class="math inline">\(\ell\)</span> but the data we are optimizing with respect to is changing over time. At each step <span class="math inline">\(t=1,\ldots,T\)</span>, we receive data vectors <span class="math inline">\(\mathbf{a}^{(1)}, \ldots, \mathbf{a}^{(T)}\)</span>. For each step <span class="math inline">\(t\)</span>, we choose a parameter vector <span class="math inline">\(\mathbf{x}^{(t)}\)</span>. After we make the prediction <span class="math inline">\(\hat{y}^{(t)} = M_{\mathbf{x}^{(t)}}(\mathbf{a}^{(t)})\)</span>, we receive the true label <span class="math inline">\(y^{(t)}\)</span>. We then use the information to choose the new parameter vector <span class="math inline">\(\mathbf{x}^{(t+1)}\)</span> for the next time step. The goal is to minimize the cumulative loss <span class="math display">\[
\mathcal{L} = \sum_{t=1}^T \ell(\hat{y}^{(t)}, y^{(t)}).
\]</span> This framework works for many loss functions and models. One popular setting is linear regression where <span class="math display">\[
\ell(\hat{y}^{(t)}, y^{(t)}) =
||\langle \mathbf{x}^{(t)}, \mathbf{a}^{(t)} \rangle - y^{(t)}||^2.
\]</span> If the model was a neural network, we could update the model to make it more complicated. If the task was classification, we could use cross-entropy loss.</p>
<p>Let’s abstract the online setting and analyze it. Instead of a single objective function with different data points, we have a sequence of objective functions <span class="math inline">\(f^{(1)}, \ldots, f^{(T)}: \mathbb{R}^d \to \mathbb{R}\)</span>. For time step <span class="math inline">\(t=1,\ldots, T\)</span>, we select a vector <span class="math inline">\(\mathbf{x}^{(t)} \in \mathbb{R}^d\)</span>. We then observe <span class="math inline">\(f_t\)</span> and pay cost <span class="math inline">\(f_t(\mathbf{x}^{(t)})\)</span>. The goal is to minimize the total cost <span class="math display">\[
\sum_{t=1}^T f_t(\mathbf{x}^{(t)}).
\]</span></p>
<p>In the offline optimization setting, we wanted to find parameters <span class="math inline">\(\hat{\mathbf{x}}\)</span> that approximately minimized the function <span class="math inline">\(f\)</span>. We will ask for a similar guarantee in the online setting. We want to choose parameters <span class="math inline">\(\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(T)}\)</span> such that <span class="math display">\[
\sum_{t=1}^T f_t(\mathbf{x}^{(t)})
\leq \left( \min_{\mathbf{x}} \sum_{t=1}^T f_t(\mathbf{x}) \right) + \epsilon.
\]</span> Amazingly, we will make no assumptions that <span class="math inline">\(f_1, \ldots, f_T\)</span> are related to each other at all!</p>
<p>In the online setting, the error <span class="math inline">\(\epsilon\)</span> is called the <em>regret</em> of our solution sequence <span class="math inline">\(\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(T)}\)</span>. Notice that the regret compares our solution sequence to the best fixed parameter in hindsight. Typically, we want <span class="math inline">\(\epsilon\)</span> to grow sublinearly in <span class="math inline">\(T\)</span> so that the average regret goes to <span class="math inline">\(0\)</span> as the number of iterations increases.</p>
<p>A surprising characteristic of the formulation is that the solution sequence could actually give a better solution than the best fixed parameter in hindsight. Perhaps we could hope for a stronger gurantee such as <span class="math display">\[
\sum_{t=1}^T f_t(\mathbf{x}^{(t)})
\leq \left( \sum_{t=1}^T \min_{\mathbf{x}} f_t(\mathbf{x}) \right) + \epsilon.
\]</span> The second guarantee differs from the first guarantee in that we are comparing our solution sequence to the optimal solution sequence that can vary wildly from one time step to the next.</p>
<p>Unfortunately, the above guarantee is not possible in general. Consider convex functions <span class="math display">\[
f_{t}(x) = | x- h_t|
\]</span> where <span class="math inline">\(h_t\)</span> is a sequence of random numbers sampled uniformly from 0 to 1. The right hand side of the above inequality is <span class="math inline">\(0\)</span> since a optimal dynamic sequence can always select <span class="math inline">\(x^{(t)} = h_t\)</span>. However, the left hand side is <span class="math inline">\(\Omega(T)\)</span> since the online solution must pay <span class="math inline">\(|x^{(t)} - h_t|\)</span> at each time step. (Because <span class="math inline">\(h_t\)</span> is random, the online solution cannot predict <span class="math inline">\(h_t\)</span> with average error less than <span class="math inline">\(\frac12\)</span>.)</p>
<p>So we’ll settle for the first, weaker guarantee that <span class="math display">\[
\sum_{t=1}^T f_t(\mathbf{x}^{(t)})
\leq \left( \min_{\mathbf{x}} \sum_{t=1}^T f_t(\mathbf{x}) \right) + \epsilon.
\]</span> There is a beautiful balance in the guarantee: If <span class="math inline">\(f_1, \ldots, f_T\)</span> are similar, we can learn to predict <span class="math inline">\(f_t\)</span> well and we can hope for a small <span class="math inline">\(\epsilon\)</span>. On the other hand, if <span class="math inline">\(f_1, \ldots, f_T\)</span> are different, we can’t hope for a small <span class="math inline">\(\epsilon\)</span> but <span class="math inline">\(\min_{\mathbf{x}} \sum_{t=1}^T f_t(\mathbf{x})\)</span> will be large. Often times, we will be in the middle of the two extremes.</p>
<p>Consider the following simple algorithm for the online problem. We start by choosing an initial parameter vector <span class="math inline">\(\mathbf{x}^{(0)}\)</span>. Then for <span class="math inline">\(t=1,\ldots, T\)</span>, we choose parameters <span class="math display">\[
\mathbf{x}^{(t)}
= \arg \min_\mathbf{x}
\sum_{j=1}^{t-1} f_{j_t}(\mathbf{x}).
\]</span> The above algorithm is called <em>follow the leader</em>. While it is simple and intuitive, the algorithm has two issues: one is related to computational complexity and one is related to accuracy. In terms of computations, the algorithm requires us to solve a convex optimization problem with on average <span class="math inline">\(O(T)\)</span> terms at each time step for total of <span class="math inline">\(O(T^2)\)</span> complexity. In terms of accuracy, the algorithm can overfit to the data. Consider the figure below where we are alternately given functions <span class="math inline">\(f_a\)</span> and <span class="math inline">\(f_b\)</span>. If we optimize after receiving slightly more <span class="math inline">\(f_a\)</span> functions, then we will overfit to <span class="math inline">\(f_a\)</span> and do poorly on <span class="math inline">\(f_b\)</span> exactly when we need to do well on <span class="math inline">\(f_b\)</span>.</p>
<p align="center">
<img src="images/hard_case.png" width="400px">
</p>
<p>Luckily, we already know an algorithm which can be modified to address both issues.</p>
</section>
<section id="online-gradient-descent" class="level2">
<h2 class="anchored" data-anchor-id="online-gradient-descent">Online Gradient Descent</h2>
<p>Online gradient descent is a modification of gradient descent for the online setting. As in the offline setting, we choose initial parameters <span class="math inline">\(\mathbf{x}^{(1)}\)</span> and learning rate <span class="math inline">\(\eta\)</span>. Then for <span class="math inline">\(t=1,\ldots, T\)</span>, we use parameters <span class="math inline">\(\mathbf{x}^{(t)}\)</span>. We then observe <span class="math inline">\(f_t\)</span> and pay cost <span class="math inline">\(f_t(\mathbf{x}^{(t)})\)</span>. Next, we update the parameter with the gradient of <span class="math inline">\(f_t\)</span>: <span class="math display">\[
\mathbf{x}^{(t+1)} = \mathbf{x}^{(t)} - \eta \nabla f_t(\mathbf{x}^{(t)}).
\]</span> Notice that if all the <span class="math inline">\(f_t\)</span> are the same, the online gradient algorithm is the same as regular gradient descent.</p>
<p>Let <span class="math display">\[
\mathbf{x}^* = \arg \min_\mathbf{x}
\sum_{t=1}^T f_t(\mathbf{x}).
\]</span> We will show that online gradient descent achieves low regret with respect to the optimal fixed solution <span class="math inline">\(\mathbf{x}^*\)</span> under our favorite assumptions.</p>
<p><strong>Regret Bound:</strong> Suppose that <span class="math inline">\(f_1, \ldots, f_T\)</span> are convex, <span class="math inline">\(G\)</span>-Lipschitz, and the gradients are <span class="math inline">\(L\)</span>-Lipschitz. Then, after <span class="math inline">\(T\)</span> steps, the regret is <span class="math display">\[
\epsilon =  \sum_{t=1}^t f_t(\mathbf{x}^{(t)})  -  \sum_{t=1}^T f_t(\mathbf{x}^*))
\leq RG \sqrt{T}.
\]</span></p>
<p>Notice that the <em>average</em> regret is bounded by <span class="math inline">\(\frac{RG}{\sqrt{T}}\)</span>. As the number of steps increases, the average regret goes to <span class="math inline">\(0\)</span>.</p>
<p>The amazing property of this result is that we made no assumptions on how <span class="math inline">\(f_1, \ldots, f_T\)</span> are related to each other. In fact, the functions could have even been chosen adversarily so that <span class="math inline">\(f_t\)</span> depends on <span class="math inline">\(\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(t-1)}\)</span>.</p>
<p>Similar to the offline setting, we will show the result with the following intermediate claim. For all <span class="math inline">\(t=1,\ldots, T\)</span>, we have <span class="math display">\[
f_t(\mathbf{x}^{(t)}) - f_t(\mathbf{x}^*)
\leq \frac{ \| \mathbf{x}^{(t)} - \mathbf{x}^* \|_2^2 - \| \mathbf{x}^{(t+1)} - \mathbf{x}^* \|_2^2}{2 \eta} + \frac{\eta G^2}{2}.
\]</span> The proof is actually the same as for the offline setting; we only use the convexity of the functions <span class="math inline">\(f_t\)</span>. Next, we’ll apply a telescoping sum to get <span class="math display">\[\begin{align*}
\sum_{t=1}^T f_t(\mathbf{x}^{(t)}) - f_t(\mathbf{x}^*)
&amp;\leq \frac{ \| \mathbf{x}^{(1)} - \mathbf{x}^* \|_2^2 - \| \mathbf{x}^{(T+1)} - \mathbf{x}^* \|_2^2}{2 \eta} + \frac{\eta TG^2}{2} \\
&amp;\leq \frac{R^2}{2\eta} + \frac{\eta TG^2}{2}
= RG\sqrt{T}
\end{align*}\]</span> where the equality follows by our choice of <span class="math inline">\(\eta = \frac{R}{G\sqrt{T}}\)</span>.</p>
<p>With the online gradient descent bound in hand, we will apply it to analyze the performance of stochastic gradient descent.</p>
</section>
<section id="stochastic-gradient-descent" class="level2">
<h2 class="anchored" data-anchor-id="stochastic-gradient-descent">Stochastic Gradient Descent</h2>
<p>In machine learning applications, we often want to minimize a function <span class="math inline">\(f\)</span> that is a sum of many functions <span class="math display">\[
f(\mathbf{x}) = \sum_{i=1}^n f_i(\mathbf{x}).
\]</span> Typically, each function <span class="math inline">\(f_i\)</span> is a loss function for a single data point.</p>
<p>Stochastic gradient descent is a modification of gradient descent that takes advantage of the finite sum structure to speed up the algorithm when there are patterns in the data.</p>
<p>The key insight of stochastic gradient descent is that we can approximate the gradient of <span class="math inline">\(f\)</span> by sampling a single function <span class="math inline">\(f_j\)</span>. To see this, observe that <span class="math display">\[
\nabla f(\mathbf{x}) = \sum_{i=1}^n \nabla f_i(\mathbf{x}).
\]</span> We will pick a random <span class="math inline">\(j \in \{1,\ldots, n\}\)</span> and then use the gradient <span class="math inline">\(\nabla f_{j}\)</span> to update our parameters. Notice that, by the definition of expectation, <span class="math display">\[
\mathbb{E}[ \nabla f_{j}(\mathbf{x}) ] =
\sum_{i=1}^n \frac1{n} \nabla f_{i}(\mathbf{x}) = \frac1{n} \nabla f(\mathbf{x}).
\]</span></p>
<p>Then <span class="math inline">\(n \nabla f_{j_t}(\mathbf{x})\)</span> is an unbiased estimator of <span class="math inline">\(\nabla f(\mathbf{x})\)</span>. The advantage is that we can typically compute <span class="math inline">\(\nabla f_{j_t}(\mathbf{x})\)</span> in <span class="math inline">\(1/n\)</span> fraction of the time it takes to compute <span class="math inline">\(f(\mathbf{x})\)</span>. Stochastic gradient trades slower convergence for cheaper iterations.</p>
<p>The stochastic gradient descent algorithm is as follows. Choose a staring vector <span class="math inline">\(\mathbf{x}^{(1)}\)</span> and learning rate <span class="math inline">\(\eta\)</span>. For <span class="math inline">\(t=1,\ldots, T\)</span>, we pick a random <span class="math inline">\(j_t \in \{1,\ldots, n\}\)</span> uniformly at random. Then we update the parameters like so <span class="math display">\[
\mathbf{x}^{(t+1)} = \mathbf{x}^{(t)} - \eta \nabla f_{j_t}(\mathbf{x}^{(t)}).
\]</span> At the end of the algorithm, we return the average parameters <span class="math display">\[
\hat{\mathbf{x}} = \frac1{T} \sum_{t=1}^T \mathbf{x}^{(t)}.
\]</span> The reason we return the average parameters at the end is because we don’t want to spend time evaluating the full function to learn which parameters are best.</p>
<!---
<p align="center">
<img src="images/sgd_vs_gd.png" width="400px">
</p>

Loss by iteration for gradient descent and stochastic gradient descent on the MNIST data set.
--->
<p>We will analyze stochastic gradient descent as a special case of online gradient descent. Consider the finite sum structure <span class="math inline">\(f(\mathbf{x}) = \sum_{i=1}^n f_i(\mathbf{x})\)</span> where each <span class="math inline">\(f_i\)</span> is convex. In addition, we assume that each <span class="math inline">\(f_i\)</span> is Lipschitz with constant <span class="math inline">\(\frac{G'}{n}\)</span>. Notice that this assumption implies that <span class="math inline">\(f\)</span> is <span class="math inline">\(G'\)</span>-Lipschitz. We will view the stochastic gradient descent algorithm as an online algorithm where we are given the functions <span class="math inline">\(f_1, \ldots, f_n\)</span>.</p>
<p>We will use the following inequality in the analysis.</p>
<p><strong>Jensen’s Inequality:</strong> For a convex function <span class="math inline">\(f\)</span> and points <span class="math inline">\(\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(T)}\)</span>, we have <span class="math display">\[
f\left(\frac1{T} \mathbf{x}^{(1)} + \ldots + \frac1{T} \mathbf{x}^{(T)} \right)
\leq \frac1{T}
f(\mathbf{x}^{(1)}) + \ldots + \frac1{T} f(\mathbf{x}^{(T)}).
\]</span></p>
<p><strong>Stochastic Gradient Descent Convergence:</strong> We will show that after <span class="math inline">\(T=\frac{R^2 G'^2}{\epsilon^2}\)</span> steps, we have <span class="math display">\[
\mathbb{E}[f(\hat{\mathbf{x}}) - f(\mathbf{x}^*)]
\leq \epsilon.
\]</span></p>
<p>First, we have that <span class="math display">\[\begin{align*}
f(\hat{\mathbf{x}}) - f(\mathbf{x}^*)
&amp;=
f\left(\frac1{T} \sum_{t=1}^T \mathbf{x}^{(t)}\right) - \frac1{T} \sum_{t=1}^T f(\mathbf{x}^*) \\
&amp;\leq \frac1{T} \sum_{t=1}^T f(\mathbf{x}^{(t)}) - \frac1{T} \sum_{t=1}^T f(\mathbf{x}^*) \\
&amp;= \frac1{T} \sum_{t=1}^T f(\mathbf{x}^{(t)}) - f(\mathbf{x}^*)
\end{align*}\]</span> where the inequality follows by Jensen’s inequality.</p>
<p>We will consider the prior inequality in expectation. Then <span class="math display">\[\begin{align*}
\mathbb{E}[f(\hat{\mathbf{x}}) - f(\mathbf{x}^*)]
&amp;\leq \frac{1}{T} \sum_{t=1}^T \mathbb{E}[f(\mathbf{x}^{(t)}) - f(\mathbf{x}^*)] \\
&amp;= \frac1{T} \sum_{t=1}^T n \mathbb{E}[f_{j_t}(\mathbf{x}^{(t)}) - f_{j_t}(\mathbf{x}^*)] \\
&amp;= \frac{n}{T} \sum_{t=1}^T \mathbb{E}[f_{j_t}(\mathbf{x}^{(t)}) - f_{j_t}(\mathbf{x}^*)].
\end{align*}\]</span> Consider the best offline solution <span class="math display">\[
\mathbf{x}^{\text{offline}} =
\arg \min_\mathbf{x} \sum_{t=1}^T f_{j_t}(\mathbf{x}).
\]</span> Notice that <span class="math display">\[
\sum_{t=1}^T f_{j_t}(\mathbf{x}^{\text{offline}})
\leq \sum_{t=1}^T f_{j_t}(\mathbf{x}^*)
\]</span> by definition. Then, combining the last two inequalities, we have <span class="math display">\[\begin{align*}
\mathbb{E}[f(\hat{\mathbf{x}}) - f(\mathbf{x}^*)]
&amp;\leq \frac{n}{T} \sum_{t=1}^T \mathbb{E}[f_{j_t}(\mathbf{x}^{(t)}) - f(\mathbf{x}^\text{offline})] \\
&amp;\leq \frac{n}{T} \left( R \frac{G'}{n} \sqrt{T} \right)
\end{align*}\]</span> where the last inequality follows by the online gradient descent guarantee.</p>
<p>Let’s compare our guarantees from gradient descent and stochastic gradient descent. For gradient descent, we can find an <span class="math inline">\(\epsilon\)</span> minimizer in <span class="math inline">\(T=\frac{R^2 G^2}{\epsilon^2}\)</span> steps. For stochastic gradient descent, we can find a <span class="math inline">\(\epsilon\)</span> minimizer in <span class="math inline">\(T=\frac{R^2 G'^2}{\epsilon^2}\)</span> steps.</p>
<p>We always have <span class="math inline">\(G \leq G'\)</span> since <span class="math display">\[\begin{align*}
\max_{\mathbf{x}} \| \nabla f(\mathbf{x}) \|_2
&amp;\leq \max_{\mathbf{x}} \sum_{i=1}^n \| \nabla f_i(\mathbf{x}) \|_2 \\
&amp;\leq \sum_{i=1}^n \max_{\mathbf{x}} \| \nabla f_i(\mathbf{x}) \|_2 \\
&amp;\leq n \frac{G'}{n} = G'.
\end{align*}\]</span> So gradient descent converges strictly faster than stochastic gradient descent. However, for a fair comparison, we should analyze the complexity of each algorithm. For gradient descent, the complexity is <span class="math inline">\(T \cdot O(n)\)</span> since each of the <span class="math inline">\(T\)</span> iterations requires us to compute the gradient of <span class="math inline">\(f\)</span> which is a sum of <span class="math inline">\(n\)</span> functions. For stochastic gradient descent, the complexity is <span class="math inline">\(T \cdot O(1)\)</span> since each of the <span class="math inline">\(T\)</span> iterations requires us to compute the gradient of a single function.</p>
<p>When <span class="math inline">\(G \ll G'\)</span>, gradient descent will perform better than stochastic gradient descent. When <span class="math inline">\(G\)</span> is closer to <span class="math inline">\(G'\)</span>, stochastic gradient descent will perform better. An extreme case when <span class="math inline">\(G = G'\)</span> is when <span class="math inline">\(f\)</span> is a sum of <span class="math inline">\(n\)</span> identical functions.</p>
<p>Let’s consider the case of unstructured data where the gradients look like random vectors. That is, each entry of <span class="math inline">\(\nabla f_i(\mathbf{x})\)</span> is a standard normal random variable. The expected norm of the gradient of a single function is <span class="math display">\[\begin{align*}
\mathbb{E}[\| \nabla f_i(\mathbf{x}) \|_2^2]
= \mathbb{E}  \left[
\sum_{j=1}^d n_{ij}^2 \right]
= d
\end{align*}\]</span> since each <span class="math inline">\(n_{ij}\)</span> has variance <span class="math inline">\(1\)</span> and mean <span class="math inline">\(0\)</span>. The expected norm of the gradient of the whole function is <span class="math display">\[\begin{align*}
\mathbb{E}[\| \nabla f(\mathbf{x}) \|_2^2]
= \mathbb{E} \left[ \left\|
\sum_{i=1}^n \nabla f_i(\mathbf{x}) \right\|_2^2 \right]
= dn
\end{align*}\]</span> since each <span class="math inline">\(\left[\sum_{i=1}^n f_i(\mathbf{x})\right]_j\)</span> has variance <span class="math inline">\(n\)</span> and mean <span class="math inline">\(0\)</span>.</p>
<p>From the analysis, we can see that random gradients are a worst case scenario for stochastic gradient descent. Generally, stochastic gradient performs better when there is more structure in the data. Luckily, structured data sets such as MNIST (shown below) are standard in machine learning.</p>
<p align="center">
<img src="images/structured.jpeg" width="300px">
</p>
</section>
<section id="preconditioning" class="level2">
<h2 class="anchored" data-anchor-id="preconditioning">Preconditioning</h2>
<p>Instead of minimizing <span class="math inline">\(f\)</span>, the idea of preconditioning is to find another function <span class="math inline">\(g\)</span> which is better suited for first order optimization but has the same minimizer as <span class="math inline">\(f\)</span>.</p>
<p><strong>Claim:</strong> Let <span class="math inline">\(h: \mathbb{R}^d \to \mathbb{R}^d\)</span> be an <em>invertible function</em>. Let <span class="math inline">\(g(\mathbf{x}) = f(h(\mathbf{x}))\)</span>. Then <span class="math display">\[
\min_\mathbf{x} f(\mathbf{x}) = \min_\mathbf{x} g(\mathbf{x}).
\]</span></p>
<p><strong>Proof:</strong> Let <span class="math inline">\(\mathbf{x}_g^* = \arg \min_\mathbf{x} g(\mathbf{x})\)</span> and <span class="math inline">\(\mathbf{x}_f^* = \arg \min_\mathbf{x} f(\mathbf{x})\)</span>. Then <span class="math display">\[\begin{align*}
\min_\mathbf{x} f(\mathbf{x}) \leq f(h(\mathbf{x}_g^*)) = g(\mathbf{x}_g^*)
\end{align*}\]</span> and <span class="math display">\[\begin{align*}
\min_\mathbf{x} g(\mathbf{x}) \leq g(h^{-1}(\mathbf{x}_f^*))
= f(h(h^{-1}(\mathbf{x}_f^*)))
= f(\mathbf{x}_f^*).
\end{align*}\]</span></p>
<p>Since <span class="math inline">\(\min_\mathbf{x} f(\mathbf{x}) \leq \min_\mathbf{x} g(\mathbf{x})\)</span> and <span class="math inline">\(\min_\mathbf{x} g(\mathbf{x}) \leq \min_\mathbf{x} f(\mathbf{x})\)</span>, the claim follows.</p>
<p>In order to optimize the function efficiently, we require that <span class="math inline">\(g\)</span> is convex. Often, we choose a linear function <span class="math inline">\(h\)</span> so <span class="math inline">\(g\)</span> is convex if <span class="math inline">\(f\)</span> is convex. In particular, let <span class="math inline">\(\mathbf{P}\)</span> be an invertible <span class="math inline">\(d \times d\)</span> matrix. So the preconditioner is given by <span class="math inline">\(g(\mathbf{x}) = f(\mathbf{P} \mathbf{x})\)</span>.</p>
<p>There are several additional goals we consider.</p>
<ul>
<li><p>We want <span class="math inline">\(g\)</span> to be better conditioned (e.g.&nbsp;smooth and strongly convex) than <span class="math inline">\(f\)</span>.</p></li>
<li><p>We want to be able to compute <span class="math inline">\(\mathbf{P}\)</span> and <span class="math inline">\(\mathbf{P}^{-1}\)</span> efficiently.</p></li>
</ul>
<p>It is often the case that <span class="math inline">\(\mathbf{P}\)</span> is chosen to be a diagonal matrix. For example, let’s consider linear regression where <span class="math inline">\(\| \mathbf{Ax} - \mathbf{b} \|_2^2\)</span>$ is the loss function, a common choice of preconditioner is <span class="math inline">\(\mathbf{P} = \text{diag}(\mathbf{A}^T \mathbf{A})^{-1}\)</span>.</p>
<p>We can think of preconditioning as variable step sizes. If <span class="math inline">\(g(\mathbf{x}) = f(\mathbf{Px})\)</span> then <span class="math inline">\(\nabla g(\mathbf{x}) = \mathbf{P}^\top \nabla f(\mathbf{Px})\)</span>.</p>
<p>If we run gradient descent on <span class="math inline">\(g\)</span>, the update is <span class="math display">\[
\mathbf{x}^{(t+1)} = \mathbf{x}^{(t)} - \eta \mathbf{P}^\top \nabla f(\mathbf{Px}^{(t)}).
\]</span></p>
<p>Multiply by <span class="math inline">\(\mathbf{P}\)</span> on both sides and let <span class="math inline">\(\mathbf{y}^{(t)} = \mathbf{Px}^{(t)}\)</span>. Then the update is <span class="math display">\[
\mathbf{y}^{(t+1)} = \mathbf{y}^{(t)} - \eta \mathbf{P}^2 \nabla f(\mathbf{y}^{(t)}).
\]</span></p>
<p>When <span class="math inline">\(\mathbf{P}\)</span> is a diagonal matrix, the reformulation in terms of <span class="math inline">\(\mathbf{y}\)</span> is just gradient descent with a different step size for each parameter.</p>
<p>There are many algorithms based on the idea of preconditioning including AdaGrad, RMSprop, and the Adam optimizer.</p>



</section>

</main> <!-- /main -->
<script>
document.addEventListener("DOMContentLoaded", function () {
  const wordsPerMinute = 200;
  const text = document.body.innerText;
  const words = text.trim().split(/\s+/).length;
  const readingTime = Math.ceil(words / wordsPerMinute);

  const readTimeEl = document.createElement("div");
  readTimeEl.innerText = `⏱️ ${readingTime} min read`;

  // Style it to appear centered
  readTimeEl.style.fontSize = "0.9em";
  readTimeEl.style.margin = "1em auto";
  readTimeEl.style.textAlign = "left";
  readTimeEl.style.width = "100%";

  const title = document.querySelector("h1");
  if (title) {
    title.parentNode.insertBefore(readTimeEl, title.nextSibling);
  }
});
</script>
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>