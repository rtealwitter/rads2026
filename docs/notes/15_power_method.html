<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.33">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Power Method</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../favicon.ico" rel="icon">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-ea385d0e468b0dd5ea5bf0780b1290d9.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-c5a5d5e27fcc88644031c24cff017230.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<link rel="shortcut icon" href="../favicon.ico">
<script id="MathJax-script" async="" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>


<!-- Google tag (gtag.js) -->
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-GZHXTPTRRE"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-GZHXTPTRRE');
</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Spring 2026</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="https://discord.gg/dES3fSPEeC"> 
<span class="menu-text">Discord</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://www.gradescope.com/courses/1091652"> 
<span class="menu-text">Gradescope</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../syllabus.html"> 
<span class="menu-text">Syllabus</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#the-lanczos-method" id="toc-the-lanczos-method" class="nav-link active" data-scroll-target="#the-lanczos-method">The Lanczos Method</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content column-page-left" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><strong>Power Method</strong></h1>
</div>



<div class="quarto-title-meta column-page-left">

    
  
    
  </div>
  


</header>


<p>Previously, we used the SVD to find the best rank-<span class="math inline">\(k\)</span> approximation to a matrix <span class="math inline">\(\mathbf{X}\)</span>. For this application, notice that we didn’t really need to find all the singular vectors and values.</p>
<p>We can save time by computing an approximate solution to the SVD. In particular, we will only compute the top <span class="math inline">\(k\)</span> singular vectors and values. We can do this with iterative algorithms that achieve time complexity <span class="math inline">\(O(ndk)\)</span> instead of <span class="math inline">\(O(nd^2)\)</span>. There are many algorithms for this problem:</p>
<ul>
<li><p><strong>Krylov subspace methods</strong> like the Lanczos method are most commonly used in practice.</p></li>
<li><p><strong>Power method</strong> is the simplest Krylov subspace method and still works very well.</p></li>
</ul>
<p>The power method computes the top right singular vector, <span class="math inline">\(\mathbf{v}_1\)</span>, of a matrix <span class="math inline">\(\mathbf{X} \in \mathbb{R}^{n\times d}\)</span> with singular value decomposition <span class="math inline">\(\mathbf{X} = \mathbf{U\Sigma V}^\top\)</span>. The method is as follows:</p>
<p align="center">
<img src="images/power.png" width="400px">
</p>
<p><strong>Power Method:</strong></p>
<ul>
<li>Choose <span class="math inline">\(\mathbf{z}^{(0)}\)</span> randomly. E.g. <span class="math inline">\(\mathbf{z}^{(0)} \sim \mathcal{N}(0,1)\)</span>.</li>
<li><span class="math inline">\(\mathbf{z}^{(0)} = \mathbf{z}^{(0)} /\|\mathbf{z}^{(0)}\|_2\)</span></li>
<li>For <span class="math inline">\(i = 1,\ldots, q\)</span>
<ul>
<li><span class="math inline">\(\mathbf{z}^{(i)} = \mathbf{X}^\top \mathbf{X} \mathbf{z}^{(i-1)} )\)</span></li>
<li><span class="math inline">\(n_i = \|\mathbf{z}^{(i)}\|_2\)</span></li>
<li><span class="math inline">\(\mathbf{z}^{(i)}  = \mathbf{z}^{(i)}/n_i\)</span></li>
</ul></li>
<li>Return <span class="math inline">\(\mathbf{z}^{(q)}\)</span></li>
</ul>
<p>In other words, each of our iterates <span class="math inline">\(\mathbf{z}^{(i)}\)</span> is simply a scaling of a column in the following matrix: <span class="math display">\[
K = \begin{bmatrix} \mathbf{z}^{(0)} &amp; \mathbf{A}\mathbf{z}^{(0)} &amp; \mathbf{A}^2 \mathbf{z}^{(0)} &amp; \mathbf{A}^3\mathbf{z}^{(0)} \ldots \mathbf{A}^q \mathbf{z}^{(0)}\end{bmatrix},
\]</span> where <span class="math inline">\(\mathbf{A} = \mathbf{X}^\top\mathbf{X}\)</span>. Typically we run <span class="math inline">\(q \ll d\)</span> iterations, so <span class="math inline">\(K\)</span> is a tall, narrow matrix. The span of <span class="math inline">\(K\)</span>’s columns is called a <strong>Krylov subspace</strong> because it is generated by starting with a single vector <span class="math inline">\(\mathbf{z}^{(0)}\)</span> and repeatedly multiplying by a fixed matrix <span class="math inline">\(A\)</span>. We will return to <span class="math inline">\(K\)</span> shortly.</p>
<section id="analysis-preliminaries" class="level4">
<h4 class="anchored" data-anchor-id="analysis-preliminaries">Analysis Preliminaries</h4>
<p>Let <span class="math inline">\(\mathbf{v}_1, \ldots, \mathbf{v}_d\)</span> be the right singular vectors of <span class="math inline">\(\mathbf{X}\)</span> (the columns of <span class="math inline">\(\mathbf{V}\)</span>). We write each iterate in terms of this basis of vectors: <span class="math display">\[
\begin{align*}
\mathbf{z}^{(0)} &amp;= c_1^{(0)}\mathbf{v}_1 + {c}_2^{(0)}\mathbf{v}_2 + \ldots + c_d^{(0)} \mathbf{v}_d \\
        \mathbf{z}^{(1)} &amp;= c_1^{(1)}\mathbf{v}_1 + {c}_2^{(1)}\mathbf{v}_2 + \ldots + c_d^{(1)} \mathbf{v}_d\\
        &amp;\vdots\\
        \mathbf{z}^{(q)} &amp;= c_1^{(q)}\mathbf{v}_1 + {c}_2^{(i)}\mathbf{v}_2 + \ldots + c_d^{(q)} \mathbf{v}_d
\end{align*}
\]</span></p>
<p>Note that <span class="math inline">\(c_j^{(i)} = \langle \mathbf{z}^{(i)}, v_i\rangle\)</span>. Intuitively, we expect the relative size of <span class="math inline">\(c_1^{(i)}\)</span> to <strong>increase</strong> in comparison to the other coefficients as <span class="math inline">\(i\)</span> increases, which is good because then <span class="math inline">\(\mathbf{z}^{(q)}\)</span> will start looking more and more like <span class="math inline">\(\mathbf{v}_1\)</span>. Why do we expect this? Because <span class="math inline">\(\mathbf{z}^{(i)} = \frac{1}{n_i}\mathbf{A}^q \mathbf{z}^{(i-1)}\)</span> and thus we can check that <span class="math inline">\(c_j^{(i)} = \frac{1}{n_i}\sigma_j^2 c^{(i-1)}_j\)</span>. The <span class="math inline">\(\frac{1}{n_i}\)</span> term is fixed for all <span class="math inline">\(j\)</span>, but the <span class="math inline">\(\sigma_j^2\)</span> term will be largest for <span class="math inline">\(j=1\)</span>, and thus the <span class="math inline">\(c_1^{(i)}\)</span> will increase in size more than any other term. We will analyze this formally soon.</p>
<p>First however, let’s see what it suffices to prove.</p>
<p><strong>Claim 1</strong>: If <span class="math inline">\(c_j^{(q)}/c_1^{(q)} \leq \sqrt{\epsilon/d}\)</span> for all <span class="math inline">\(j\neq 1\)</span> than either <span class="math inline">\(\|\mathbf{v}_1 -\mathbf{z}^{(q)}\|_2^2\leq 2\epsilon\)</span> or <span class="math inline">\(\|-\mathbf{v}_1 - \mathbf{z}^{(q)}\|_2^2\leq 2\epsilon\)</span> .</p>
<p><em>Proof.</em> Since <span class="math inline">\(c_1^{(q)} \leq 1\)</span>, the above would imply that <span class="math inline">\(c_j^{(q)} \leq \sqrt{\epsilon/d}\)</span>. Since <span class="math inline">\(\sum_{k=1}^d \left(c_k^{(q)}\right)^2 = 1\)</span> it follows that <span class="math inline">\(\left(c_1^{(q)}\right)^2 \geq (1-\epsilon)\)</span> and thus <span class="math inline">\(\left|c_1^{(q)}\right| \geq 1-\epsilon\)</span>. Then for any unit vector <span class="math inline">\(\mathbf{x}\)</span> we have <span class="math inline">\(\|\mathbf{x} -\mathbf{z}^{(q)}\|_2^2 = 2 - 2\langle\mathbf{x},\mathbf{z}^{(q)}\rangle\)</span>. Since <span class="math inline">\(\langle\mathbf{v}_1,\mathbf{z}^{(q)}\rangle = c_1^{(q)}\)</span> we conclude that either <span class="math inline">\(\langle\mathbf{v}_1,\mathbf{z}^{(q)}\rangle \geq 1-\epsilon\)</span> or <span class="math inline">\(\langle- \mathbf{v}_1,\mathbf{z}^{(q)}\rangle \geq 1-\epsilon\)</span>. Suppose without loss of generality it’s the first: <span class="math inline">\(\langle\mathbf{v}_1,\mathbf{z}^{(q)}\rangle \geq 1-\epsilon\)</span>. Then we would conclude that <span class="math inline">\(\|\mathbf{v}_1 -\mathbf{z}^{(q)}\|_2 = 2 - 2\langle\mathbf{v}_1,\mathbf{z}^{(q)}\rangle \leq 2 - 2\cdot (1-\epsilon) = 2\epsilon\)</span>. <span class="math inline">\(\square\)</span></p>
<p>So, to show power methods converges, our goal is to prove that <span class="math inline">\(\left|c_j^{(q)}/c_1^{(q)}\right| \leq \sqrt{\epsilon/d}\)</span> for all <span class="math inline">\(j\neq 1\)</span>.</p>
</section>
<section id="heart-of-the-analysis" class="level4">
<h4 class="anchored" data-anchor-id="heart-of-the-analysis">Heart of the Analysis</h4>
<p>To prove this bound, we note that <span class="math inline">\(c_j^{(q)} = S\cdot \sigma_j^{2q} c_j^{(0)}\)</span> for any <span class="math inline">\(j\)</span> and <span class="math inline">\(c_1^{(q)} = S\cdot \sigma_1^{2q} c_1^{(0)}\)</span> where <span class="math inline">\(S = 1/\prod_{i=1}^q n_i\)</span> is some fixed scaling. So: <span class="math display">\[
\left|\frac{c_j^{(q)} }{c_1^{(q)} }\right| = (\sigma_j/\sigma_1)^{2q} \left|\frac{c_j^{(0)} }{c_1^{(0)} }\right|.
\]</span> As claimed in class (and can be prove as an exercise – try using rotational invariance of the Gaussian ) if <span class="math inline">\(z^{(0)}\)</span> is a randomly initialized start vector, <span class="math inline">\(\left|\frac{c_j^{(0)} }{c_1^{(0)} }\right| \leq d^{3}\)</span> with high probability. That may seem like a lot, but <span class="math inline">\((\sigma_j/\sigma_1)^{2q}\)</span> is going to be a tiny number, so will easily cancel that out. In particular, <span class="math display">\[
(\sigma_j/\sigma_1)^{2q} = \left(1-\frac{\sigma_1-\sigma_j}{\sigma_1}\right)^{2q} \leq (1-\gamma)^{2q},
\]</span> where <span class="math inline">\(\gamma = \frac{\sigma_1-\sigma_2}{\sigma_1}\)</span> is our spectral gap parameter. As long as we set <span class="math display">\[
q = \frac{\log(d^3\sqrt{d/\epsilon})}{\gamma} = O\left(\frac{\log(d/\epsilon)}{\gamma}\right),
\]</span> then <span class="math inline">\((1-\gamma)^{2q} \leq \frac{\sqrt{\epsilon/d}}{d^3}\)</span>, and thus <span class="math display">\[
\left|\frac{c_j^{(q)} }{c_1^{(q)} }\right| = (\sigma_j/\sigma_1)^{2q} \left|\frac{c_j^{(0)} }{c_1^{(0)} }\right| \leq d^3\cdot \frac{\sqrt{\epsilon/d}}{d^3} \leq \sqrt{\epsilon/d},
\]</span> as desired.</p>
</section>
<section id="alternative-guarantee" class="level4">
<h4 class="anchored" data-anchor-id="alternative-guarantee">Alternative Guarantee</h4>
<p>In machine learning applications, we care less about actually approximating <span class="math inline">\(\mathbf{v}_1\)</span>, and more that the <span class="math inline">\(\mathbf{z}\)</span> is a “good top singular vector” in that it offers a good rank-1 approximation to <span class="math inline">\(\mathbf{X}\)</span>. Tha tis, we want to prove that <span class="math display">\[\|\mathbf{X} - \mathbf{X}\mathbf{z}\mathbf{z}^\top\|_F^2 = \|\mathbf{X}\|_F^2 - \|\mathbf{X}\mathbf{z}\mathbf{z}^\top\|_F^2\]</span> is small, or equivalently, that <span class="math display">\[\|\mathbf{X}\mathbf{z}\mathbf{z}^\top\|_F^2\]</span> is large. The largest it could be is <span class="math inline">\(\|\mathbf{X}\mathbf{v}_1\mathbf{v}_1^\top\|_F^2 = \sigma_1^2\)</span>. And from the same argument above, where we claimed that either <span class="math inline">\(\langle\mathbf{v}_1,\mathbf{z}^{(q)}\rangle \geq 1-\epsilon\)</span> or <span class="math inline">\(\langle- \mathbf{v}_1,\mathbf{z}^{(q)}\rangle \geq 1-\epsilon\)</span>, it is not hard to check that <span class="math display">\[\|\mathbf{X}\mathbf{z}\mathbf{z}^\top\|_F^2 \geq (1-\epsilon)^2 \sigma_1^2,\]</span> so after <span class="math inline">\(O\left(\frac{\log(d/\epsilon)}{\gamma}\right)\)</span> iterations we get a near optimal low-rank approximation.</p>
</section>
<section id="the-lanczos-method" class="level2">
<h2 class="anchored" data-anchor-id="the-lanczos-method">The Lanczos Method</h2>
<p>We will now see how to improve on power method using what is known as the Lanczos method. Like power method, Lanczos is considered a <strong>Krylov subspace method</strong> because it will return a solution <strong>in the span of the Krylov subspace</strong> that we introduced before. Power method clearly does this – it returns a scaling of the last column of <span class="math inline">\(K\)</span>. The whole idea behind Lanczos is to avoid “throwing away’” information from earlier columns like power method, but instead to take advantage of the whole space. It turns at that doing so can be very helpful – we will get a bound that depends on <span class="math inline">\(1/\sqrt{\gamma}\)</span> instead of <span class="math inline">\(1/\gamma\)</span>.</p>
<p>Specifically, to define the Lanczos method, we will let <span class="math inline">\(\mathbf{Q}\in \mathbb{R}^{d\times k}\)</span> be a matrix with orthonormal columns that spans <span class="math inline">\(K\)</span>. In practice, you need to be careful about how this is computed for numerical stability reasons, but we won’t worry about that for now. Imagine your computer has infinite precision and we just compute <span class="math inline">\(\mathbf{Q}\)</span> by orthonormalizing <span class="math inline">\(K\)</span>.</p>
<p><strong>Lanczos Method</strong></p>
<ul>
<li>Compute an orthonormal span <span class="math inline">\(\mathbf{Q}\)</span> for the degree <span class="math inline">\(q\)</span> Krylov subspace.</li>
<li>Let <span class="math inline">\(\mathbf{z}\)</span> be the top eigenvector of <span class="math inline">\(\mathbf{Q}^\top \mathbf{A}\mathbf{Q} = \mathbf{Q}^\top \mathbf{X}^\top \mathbf{X} \mathbf{Q}\)</span></li>
<li>Return <span class="math inline">\(\mathbf{Q} \mathbf{z}\)</span>.</li>
</ul>
<p>Importantly, the first step only requires <span class="math inline">\(q\)</span> matrix-vector multiplications with <span class="math inline">\(\mathbf{X}^\top\mathbf{X}\)</span>, each of which can be implemented in <span class="math inline">\(O(nd)\)</span> time, just like we did for power method. The second step might look a bit circular at first glance. We want an approximation algorithm for computing the top eigenvector of <span class="math inline">\({\mathbf{X}}^\top\mathbf{X}\)</span> and the above method uses a top eigenvector algorithm as a subroutine. But note that <span class="math inline">\(\mathbf{Q}^\top {\mathbf{AQ}}\)</span> only has size <span class="math inline">\(q\times q\)</span>, where <span class="math inline">\(q\ll d\)</span> is our iteration count. So even if it’s too expensive to compute a direct eigendecomposition of <span class="math inline">\(\mathbf{X}^\top\mathbf{X}\)</span>, <span class="math inline">\({\mathbf{Q}}^\top{\mathbf{X}}^\top{\mathbf{X}}{\mathbf{Q}}\)</span> can be computed in <span class="math inline">\(O(ndq) + O(dq^2) + O(q^3) + O(ndq)\)</span> time (the first part is the time to construct <span class="math inline">\(\mathbf{Q}\)</span> and <span class="math inline">\(\mathbf{X}\mathbf{Q}\)</span>, the second to compute <span class="math inline">\({\mathbf{Q}}^\top{\mathbf{X}}^\top{\mathbf{X}}{\mathbf{Q}}\)</span>, and the third to find its top eigenvector using a direct method).</p>
<section id="analysis-preliminaries-1" class="level4">
<h4 class="anchored" data-anchor-id="analysis-preliminaries-1">Analysis Preliminaries</h4>
<p>Our first claim is that Lanczos returns the <em>best</em> approximate singular vector in the span of the Krylov subspace. Then we will argue that there always exists <em>some</em> vector in the span of the subspace that is significantly better than what power method returns, so the Lanczos solution must be significantly better as well.</p>
<p><strong>Claim 2</strong>: Amongst all vectors in the span of the Krylov subspace (i.e., any vector <span class="math inline">\(\mathbf{y}\)</span> that can be written as <span class="math inline">\(\mathbf{y} = \mathbf{Q}\mathbf{x}\)</span> for some <span class="math inline">\(x\in \mathbb{R}^k\)</span>), <span class="math inline">\(\mathbf{y}^* = \mathbf{Q}\mathbf{z}\)</span> minimizes the low-rank approximation error <span class="math inline">\(\|\mathbf{X} - \mathbf{X}\mathbf{y}\mathbf{y}^\top\|_F^2\)</span>.</p>
<p><em>Proof.</em> First, we can prove that <span class="math inline">\(\mathbf{y}\)</span> should always be chosen to have unit norm, so that <span class="math inline">\(\mathbf{y}\mathbf{y}^\top\)</span> is a projection. Accordingly, it must also be that <span class="math inline">\(\mathbf{x} = \mathbf{Q}^\top\mathbf{y}\)</span> has unit norm. Then, proving the claim above is equivalent to proving that <span class="math inline">\(\mathbf{y}^* = {\mathbf{Q}}\mathbf{z}\)</span> maximizes <span class="math inline">\(\|\mathbf{X}\mathbf{y}\mathbf{y}^\top\|_F^2 = \|\mathbf{X}\mathbf{y}\|_F^2 = \|\mathbf{X}\mathbf{y}\|_2^2 = \|\mathbf{X}\mathbf{Q}\mathbf{x}\|_2^2\)</span>. It is not hard to check that setting <span class="math inline">\(\mathbf{x}\)</span> to be the maximum right singular vector of <span class="math inline">\({\mathbf{X}}{\mathbf{Q}}\)</span> maximizes this <span class="math inline">\(\|\mathbf{X}\mathbf{Q}\mathbf{x}\|_2^2\)</span> amongst all unit vectors, and this right singular vector is the same at the top eigenvector of <span class="math inline">\(\mathbf{Q}^\top \mathbf{X}^\top \mathbf{X} \mathbf{Q}\)</span>.</p>
<p><strong>Claim 3</strong>: If we run the Lanczos method for <span class="math inline">\(O\left(\frac{\log(d/\epsilon)}{\sqrt{\gamma}}\right)\)</span> There is <em>some</em> vector <span class="math inline">\(\mathbf{w}\)</span> of the form <span class="math inline">\(\mathbf{w} = \mathbf{Q}\mathbf{x}\)</span> such that either <span class="math inline">\(\langle\mathbf{v}_1,\mathbf{w}\rangle \geq 1-\epsilon\)</span> or <span class="math inline">\(\langle- \mathbf{v}_1,\mathbf{w}\rangle \geq 1-\epsilon\)</span>.</p>
<p>In other words, there is some <span class="math inline">\(\mathbf{w}\)</span> in the Krylov subspace that has a large inner product with the true top singular vector <span class="math inline">\(\mathbf{v}_1\)</span>. As seen earlier for power method, this can be used to prove that e.g.&nbsp;<span class="math inline">\(\|\mathbf{X}\mathbf{w}\mathbf{w}^\top\|_F^2\)</span> is large, and from <strong>Claim 2</strong>, we know that the <span class="math inline">\(\mathbf{v}\)</span> returned by Lanczos can only do better. So, we focus on proving <strong>Claim 3</strong>.</p>
</section>
<section id="heart-of-the-analysis-1" class="level4">
<h4 class="anchored" data-anchor-id="heart-of-the-analysis-1">Heart of the Analysis</h4>
<p>The key idea is to observe that any vector in the span of the Krylov subspace of size <span class="math inline">\(q\)</span> – i.e.&nbsp;any vector <span class="math inline">\(\mathbf{w}\)</span> that can be written <span class="math inline">\(\mathbf{w} = \mathbf{Q}\mathbf{x}\)</span> is equal to: <span class="math display">\[
\mathbf{w} = p(\mathbf{A})\mathbf{z}^{(0)},
\]</span> for some <strong>degree q polynomial</strong> <span class="math inline">\(p\)</span>. For example, we might have <span class="math inline">\(p(\mathbf{A}) = 2\mathbf{\mathbf{A}}^2 - 4\mathbf{A}^3 + \mathbf{A}^6\)</span> or <span class="math inline">\(p(\mathbf{A}) = I - \mathbf{A} - 10\mathbf{A}^5\)</span>. And moreover, for any degree <span class="math inline">\(q\)</span> polynomial <span class="math inline">\(p\)</span>, there is <em>some</em> <span class="math inline">\(\mathbf{x}\)</span> such that <span class="math inline">\(\mathbf{Q}\mathbf{x} = p(\mathbf{A})\mathbf{z}^{(0)}\)</span>. To see that this is true, we note that all of the monomials <span class="math inline">\(\mathbf{z}^{(0)}, A\mathbf{z}^{(0)}, \ldots, \mathbf{A}^q\mathbf{z}^{(0)}\)</span> lie in the span of <span class="math inline">\(\mathbf{Q}\)</span>, so any linear combination does as well.</p>
<p>This means that showing there is a good approximate top singular vector <span class="math inline">\(\mathbf{w}\)</span> in the span of the Krylov subspace can be reduced to finding a <strong>good polynomial <span class="math inline">\(p(\mathbf{A})\)</span></strong>. Specifically, notice that, if we write <span class="math inline">\(p(\mathbf{A})\mathbf{z}^{(0)}\)</span> in the span of the singular vectors we have: <span class="math display">\[
p(\mathbf{A})\mathbf{z}^{(0)} = g_1 \mathbf{v}_1 + g_2 \mathbf{v}_2 + \ldots + g_d \mathbf{v}_d
\]</span> where <span class="math display">\[
g_j = c_j^{(0)}p(\sigma_j^2).
\]</span> Our goal, which is exactly the same as when we analyzed power method, is to show that <span class="math inline">\(g_1\)</span> is <em>much larger</em> than <span class="math inline">\(g_j\)</span> for all <span class="math inline">\(j \neq 1\)</span>. In other words we want to find a polynomial such that <span class="math inline">\(p(t)\)</span> is small for all values of <span class="math inline">\(0\leq t&lt; \sigma_1^2\)</span>, but then the polynomial should suddenly <strong>jump</strong> to be large at <span class="math inline">\(\sigma_1\)</span>. The simplest degree <span class="math inline">\(q\)</span> polynomial that does this is <span class="math inline">\(p(t) = t^q\)</span>. However, it turns out there are more <em>sharply</em> jumping polynomials, which can be obtained by shifting/scaling a type of polynomials known as a <a href="https://en.wikipedia.org/wiki/Chebyshev_polynomials">Chebyshev polynomial</a>. An example that jumps at <span class="math inline">\(\sigma_1^2 = 1\)</span> is shown below. The difference from <span class="math inline">\(t^q\)</span> is pretty remarkable – even though the polynomial <span class="math inline">\(p\)</span> shown below is nearly as small for all <span class="math inline">\(0\leq t&lt; 1\)</span>, it is much larger at <span class="math inline">\(t=1\)</span>.</p>
<p align="center">
<img src="images/basic_jump.png" width="400px">
</p>
<p align="center">
<img src="images/cheby_jump.png" width="400px">
</p>
<p>Concretely we can claim the following, which is a bit tricky to prove, but well known (see <a href="https://arxiv.org/pdf/1504.05477.pdf">Lemma 5 here</a> for a full proof).</p>
<p><strong>Claim 4:</strong> There is a degree <span class="math inline">\(O\left(\sqrt{\frac{1}{\gamma}}\log\frac{1}{\epsilon}\right)\)</span> degree polynomial <span class="math inline">\(\hat{p}\)</span> such that <span class="math inline">\(\hat{p}(1) = 1\)</span> and <span class="math inline">\(|p(t)| \leq \epsilon\)</span> for <span class="math inline">\(0 \leq t \leq 1-\gamma\)</span>.</p>
<p>In contrast, to ensure that <span class="math inline">\(t^q\)</span> satisfies the above, we would need degree q = <span class="math inline">\(O\left({\frac{1}{\gamma}\log\frac{1}{\epsilon}}\right)\)</span> – a quadratically worse bound. This is what will account for the quadratic difference in performance between the Lanczos and Power Methods.</p>
<p>The fact that there exist much steeper low-degree polynomails than <span class="math inline">\(t^q\)</span> is the sort of thing studied in the mathematical field known as Approximation Theory. That might seem pretty obscure, but steep polynomials are surprisingly useful in computer science, appearing everywhere from <a href="https://dl.acm.org/doi/10.1145/129712.129757">classic</a>, to <a href="https://arxiv.org/pdf/quant-ph/9802049.pdf">Quantum complexity theory</a>, to <a href="http://www.cs.columbia.edu/~rocco/Public/stoc01.pdf">learning theory</a>. If you’re interested in learning more about this, check out slides for this <a href="http://people.cs.georgetown.edu/jthaler/QuICSslides.pdf">talk</a>.</p>
</section>
<section id="finishing-up" class="level4">
<h4 class="anchored" data-anchor-id="finishing-up">Finishing Up</h4>
<p>Finally, we use <strong>Claim 4</strong> to finish the analysis of Lanczos. Consider the vector <span class="math inline">\(\hat{p}\left(\frac{1}{\sigma_1^2}A\right)\mathbf{z}^{(0)}\)</span>, which as argued above lies in the Krylov subspace. As discussed before, our job is to prove that: <span class="math display">\[
\frac{c_j^{(0)}\hat{p}\left(\frac{1}{\sigma_1^2}\sigma_j^2\right)}{c_1^{(0)}\hat{p}\left(\frac{1}{\sigma_1^2}\sigma_1^2\right)} \leq \sqrt{\epsilon/d},
\]</span> for all <span class="math inline">\(j \neq i\)</span>, as long as <span class="math inline">\(\hat{p}\)</span> is chosen to have degree <span class="math inline">\(q = O\left(\sqrt{\frac{1}{\gamma}}\log\frac{d}{\epsilon}\right)\)</span></p>
<p>Consider the numerator first. <span class="math inline">\(\frac{\sigma_j^2}{\sigma_1^2} = \left(\frac{\sigma_j}{\sigma_1}\right)^2 = \left(1 - \left(1-\frac{\sigma_j}{\sigma_1}\right)\right)^2 = \left(1 - \frac{\sigma_1 - \sigma_j}{\sigma_1}\right)^2 \leq (1-\gamma)^2 \leq (1-\gamma)\)</span> .</p>
<p>Accordingly, if we set <span class="math inline">\(q = O\left(\sqrt{\frac{1}{\gamma}}\log\frac{1}{\epsilon'}\right)\)</span> where <span class="math inline">\(\epsilon' = \sqrt{\epsilon/d}/d^3\)</span>, then <span class="math inline">\(\hat{p}\left(\frac{1}{\sigma_1^2}\sigma_j^2\right) \leq \epsilon'\)</span>. And the denomenator is simply equal to <span class="math inline">\(c_1^{(0)}\hat{p}(1) =  c_1^{(0)}\cdot 1\)</span>. So, since <span class="math inline">\(c_j^{(0)}/c_1^{(0)}\leq d^3\)</span> with high probability, as argued earlier, the equation holds. And thus <strong>Claim 3</strong> is proven by setting <span class="math inline">\(\mathbf{w} = \hat{p}\left(\frac{1}{\sigma_1^2} \mathbf{A} \right)\mathbf{z}^{(0)}\)</span>.</p>
<!--
### Power Method

We'll focus on the power method since it is the simplest to understand.
For exposition, we'll assume that $k=1$.
Our goal is to find a vector $\mathbf{z} \approx \mathbf{v}_1$ where $\mathbf{v}_1$ is the top singular vector of $\mathbf{X}$.

We start with a randomly initialized vector
$$
\mathbf{z}^{(0)} \sim \mathcal{N}(0, \mathbf{I}).
$$
We will see why it is important that $\mathbf{z}^{(0)}$ is rotationally invariant later.
We will then normalize $\mathbf{z}^{(0)}$ to have unit length so $\mathbf{z}^{(0)} = \mathbf{z}^{(0)} / \| \mathbf{z}^{(0)} \|_2$.
For each iteration $t = 1, \ldots, T$, we will compute
$$
\mathbf{z}^{(i)} = \mathbf{X}^\top \mathbf{X} \mathbf{z}^{(i-1)} \qquad n_t = \| \mathbf{z}^{(i)} \|_2.
$$
and then re-normalize so $\mathbf{z}^{(i)} = \mathbf{z}^{(i)} / n_t$.
Finally, we return $\mathbf{z}^{(T)}$.

The method is called the power method because each iterate looks a matrix raised to a power
$$
\mathbf{z}^{(t)} = (\mathbf{X}^\top \mathbf{X})^\top \mathbf{z}^{(0)}.
$$
The run time of the algorithm is $T O(nd)$ if we use matrix-vector multiplications to compute $\mathbf{X}^\top(\mathbf{X} \mathbf{z}^{(i-1)})$.

As the algorithm runs, the vector $\mathbf{z}^{(t)}$ converges to the top singular vector $\mathbf{v}_1$.

We will prove the following convergence theorem.

**Basic Power Method Convergence:**
Let $\gamma = \frac{\sigma_1 - \sigma_2}{\sigma_1}$ be a parameter capture the *gap* between the first and second largest singular values. If power method is initialized with a random Gaussian vector then, with high probability after $T = O \left( \frac{\log d/\epsilon}{\gamma} \right)$ iterations, we have either
$$
\| \mathbf{v}_1 - \mathbf{z}^{(T)} \|_2 \leq \epsilon
\qquad \text{or} \qquad
\| \mathbf{v}_1 + \mathbf{z}^{(T)} \|_2 \leq \epsilon.
$$

We have the two possible guarantees because we will recover $\mathbf{v}_1$ or $-\mathbf{v}_1$ depending on the sign of the first entry of $\mathbf{v}_1$.

The total time complexity is $O \left( nd \frac{\log d/\epsilon}{\gamma} \right)$.

We can verify that we have found a good approximation to $\mathbf{v}_1$ by checking whether $\mathbf{X}^\top \mathbf{X} \mathbf{z}^{(T)}$ is close to $\sigma \mathbf{z}^{(T)}$ for some scalar $\sigma$.
Notice that this is equivalent to checking the distance between two iterates.

We will prove the theorem by writing each iterate $\mathbf{z}^{(t)}$ in terms of the singular vectors $\mathbf{v}_1, \ldots \mathbf{v}_d$.

We can write
\begin{align*}
\mathbf{z}^{(t)}
= c_1^{(t)} \mathbf{v}_1 + \ldots + c_d^{(t)} \mathbf{v}_d
\end{align*}
where $[c_1^{(t)}, \ldots, c_d^{(t)}] = \mathbf{c}^{(t)} = \mathbf{V}^\top \mathbf{z}^{(t)}$ .
Since $\mathbf{V}$ is orthogonal, notice that
$\| \mathbf{z}^{(t)} \|_2 = 1$ implies that
$\| \mathbf{c}^{(t)} \|_2 = 1$.

We will focus on a single iteration $t$ and a single component $j$ of the iterate
We have that
$$
c_j^{(t)} = \sigma_j^2 c_j^{(t-1)} \frac1{n_t}
$$

Notice that $\mathbf{X}^\top \mathbf{X} = \mathbf{V} \mathbf{\Sigma} \mathbf{U}^\top \mathbf{U} \mathbf{\Sigma} \mathbf{V}^\top = \mathbf{V} \mathbf{\Sigma}^2 \mathbf{V}^\top$.

So then 
\begin{align*}
\mathbf{z}^{(t)}
= \frac1{n_t}
\mathbf{X}^\top \mathbf{X} \mathbf{z}^{(t-1)}
= \frac1{n_t}
\mathbf{V} \mathbf{\Sigma}^2 \mathbf{V}^\top \mathbf{z}^{(t-1)}
= \frac1{n_t} \mathbf{V} \mathbf{\Sigma}^2 \mathbf{c}^{(t-1)}.
\end{align*}

This operation composes after $T$ updates.
So we can write
\begin{align*}
\mathbf{z}^{(T)}
= \frac1{\prod_{t=1}^\top n_t} 
\left[ c_1^{(1)} \sigma_1^{2T}
\mathbf{v}_1 + c_2^{(1)} \sigma_2^{2T}
\mathbf{v}_2 + \ldots + c_d^{(1)} \sigma_d^{2T} \mathbf{v}_d
\right].
\end{align*}

Let $\alpha_j = \frac1{\prod_{t=1}^\top n_t} c_j^{(0)} \sigma_j^{2T}$.
We want to show that $\alpha_j \ll \epsilon$ for $j \neq 1$.

Since $\mathbf{z}^{(T)} is a unit vector,
$\sum_{i=1}^d \alpha_i^2 = 1$ so $|\alpha_1| \leq 1.
If we can prove that
$|\frac{\alpha_j}{\alpha_1}| \leq \sqrt{\frac{\epsilon}{2d}}$ then we will have that
$\| \mathbf{v}_1 - \mathbf{z}^{(T)} \|_2^2 \leq \epsilon$
since
\begin{align*}
\alpha_j^2 &\leq \alpha_1^2 \frac{\epsilon}{2d} \\
1 = \alpha_1^2 + \sum_{j=2}^d \alpha_d^2 &\leq \alpha_1^2 + \frac{\epsilon}{2} \\
\alpha_1^2 &\geq 1 - \frac{\epsilon}{2} \\
|\alpha_1| \geq 1 - \frac{\epsilon}{2}.
\end{align*}

Let's see how many steps it takes to ensure that $|\frac{\alpha_j}{\alpha_1}| \leq \sqrt{\frac{\epsilon}{2d}}$.

We will assume that the starting coefficient on the the first singular vector is not too small.
In particular,
$$
|c_1^{(0)}| \geq O \left( \frac1{\sqrt{d}} \right).
$$

TODO: Put in here


We have seen concentration results many times before.
Today, we'll use an *anti*concentration result.
We'll use the rotational invariance of the Gaussian to observe that
$$
\mathbf{c}^{(0)} = \frac{\mathbf{V}^\top \mathbf{z}^{(0)}}{\| \mathbf{z}^{(0)} \|_2} 
= \frac{\mathbf{V}^\top \mathbf{z}^{(0)}}{\| \mathbf{V}^\top \mathbf{z}^{(0)} \|_2}
\sim \frac{\mathbf{g}}{\| \mathbf{g} \|_2}
$$
where $\mathbf{g} \sim \mathcal{N}(0,\mathbf{I})$.

We need to show that with high probabiity, the first entry of $\frac{\mathbf{g} } {\| \mathbf{g} \|_2} \geq c \frac1{\sqrt{d}}$ for some constant $c$.

With high probability, $\| \mathbf{g} \|_2 \leq 2d$
since $\mathbb{E}[\| \mathbf{g} \|_2^2] = d$.

In addition, with probability $1-O(\alpha)$, we have $g_1 \geq \alpha$.
To see this, observe that

TODO: Integral argument

In the theorem assumptions, we needed $\gamma$ to be reasonably large. 
If $\gamma$ is too small, the power method truly won't converge to the top eigenvector.
However, if we change our goal slightly, this is not a problem.
In particular, no matter how small $\gamma$ is,
after $T = O \left( \frac{\log d/\epsilon}{\epsilon} \right)$ iterations, we have
$$
\| \mathbf{X} - \mathbf{X} \mathbf{z}^{(T)} \mathbf{z}^{(T)^\top} \|_F^2
\leq (1-\epsilon) \| \mathbf{X} - \mathbf{X} \mathbf{v}_1 \mathbf{v}_1^\top \|_F^2.
$$

The intution is that, for a good low-rank approximation, we don't actually need to converge to $\mathbf{v}_1$ if $\sigma_1$ and $\sigma_2$ are the same or very close.
It suffices to return $\mathbf{v}_1$ or $\mathbf{v}_2$ or some linear combination of the two.

## More Iterative Methods

We won't give guarantees for it but we can also use the power method to find the top $k$ singular vectors.
The power method for larger $k$ is known under many names including the block power method, the simultaneous iteration method, the subspace iteration method, and the orthogonal iteration method.

The difference between the power method for $k=1$ and larger $k$ is that we iterate with a matrix instead of a vector.
In particular, we intitialize $\mathbf{G} \in \mathbb{R}^{d \times k}$ with i.i.d. Gaussian entries.
Instead of normalizing, we orthonormalize by finding an orthonormal basis for the column span
$$
\mathbf{Z}^{(0)} = \text{orth}(\mathbf{G}
$$
The update is then given by
$$
\mathbf{Z}^{(t)} = \mathbf{X}^\top (\mathbf{X} \mathbf{Z}^{(t-1)})
$$
and we again normalize
$$
\mathbf{Z}^{(t)} = \text{orth}(\mathbf{Z}^{(t)}.
$$

Since the matrices we are orthnormalizing are $d \times k$, we can orthonormalize them in $O(dk^2)$ time.
The guarantee of the block power method is that, after $T= \left( \frac{\log d/\epsilon}{\gamma} \right)$ iterations, we have
$$
\| \mathbf{X} - \mathbf{Z}^{(T)} \mathbf{Z}^{(T)^\top} \|_F^2
\leq (1+\epsilon) \| \mathbf{X} - \mathbf{X} \mathbf{V}_k \mathbf{V}_k^\top \|_F^2.
$$

The time complexity is $O(\text{nnz}(\mathbf{X}) k T) \leq O(ndk T)$
where $\text{nnz}(\mathbf{X})$ is the number of non-zero entries in $\mathbf{X}$.

It is possible to accelerate these methods
to $T=\left( \frac{\log d /\epsilon}{\sqrt{\epsilon}} \right)$ iterations.
Generally, the idea is to use all the iterates instead of just the last one.

For Krylov methods, we save the subspace
$$
\mathcal{K}_q =
[\mathbf{g}, (\mathbf{X}^\top \mathbf{X}) \mathbf{g}, \ldots, (\mathbf{X}^\top \mathbf{X})^{q-1} \mathbf{g}].
$$

The Lanczos method in particular finds an orthonormal span $\mathbf{Q} \in \mathbb{R}^{d \times k}$ for the vectors in $\mathcal{K}_q$.
We then solve the problem
$$
\min_{\mathbf{v} = \mathbf{Qw}} \| \mathbf{X} - \mathbf{X v v}^\top \|_F^2.
$$

The method finds the best vector in the Krylov subspace, instead of just using the last vector.
We can run the method in $O(ndk + dk^2)$ time.
This is the approach implemented in high performance linear algebra functions like $\texttt{svds}$ in MATLAB and $\texttt{eigs}$ in Python.

For a degree $t$ polynomial $p$, let 
$$\mathbf{v}_p = \frac{p(\mathbf{X}^\top \mathbf{X})\mathbf{g})}{\| p(\mathbf{X}^\top \mathbf{X)) \mathbf{g}\|_2}.$$
We always have that $\mathbf{v}_p \in \mathcal{K}_t$ since the Krylov subspace contains the first $t$ powers of $\mathbf{X}^\top \mathbf{X}$ applied to $\mathbf{g}$.

The power method simply returns $\mathbf{v}_{x^\top}$
whereas the Lanczos method returns the best 
$\mathbf{v}_p^*$
where
$$
p^* = \arg \min_{\text{degree} t p} \| \mathbf{X} - \mathbf{X} \mathbf{v}_p \mathbf{v}_p^\top \|_F^2.
$$
-->



</section>
</section>

</main> <!-- /main -->
<script>
document.addEventListener("DOMContentLoaded", function () {
  const wordsPerMinute = 200;
  const text = document.body.innerText;
  const words = text.trim().split(/\s+/).length;
  const readingTime = Math.ceil(words / wordsPerMinute);

  const readTimeEl = document.createElement("div");
  readTimeEl.innerText = `⏱️ ${readingTime} min read`;

  // Style it to appear centered
  readTimeEl.style.fontSize = "0.9em";
  readTimeEl.style.margin = "1em auto";
  readTimeEl.style.textAlign = "left";
  readTimeEl.style.width = "100%";

  const title = document.querySelector("h1");
  if (title) {
    title.parentNode.insertBefore(readTimeEl, title.nextSibling);
  }
});
</script>
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>