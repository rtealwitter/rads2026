<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.33">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Spectral Graph Theory</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../favicon.ico" rel="icon">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-ea385d0e468b0dd5ea5bf0780b1290d9.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-c5a5d5e27fcc88644031c24cff017230.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<link rel="shortcut icon" href="../favicon.ico">
<script id="MathJax-script" async="" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>


<!-- Google tag (gtag.js) -->
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-GZHXTPTRRE"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-GZHXTPTRRE');
</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Spring 2026</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="https://discord.gg/dES3fSPEeC"> 
<span class="menu-text">Discord</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://www.gradescope.com/courses/1091652"> 
<span class="menu-text">Gradescope</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../syllabus.html"> 
<span class="menu-text">Syllabus</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#spectral-clustering" id="toc-spectral-clustering" class="nav-link active" data-scroll-target="#spectral-clustering">Spectral Clustering</a>
  <ul class="collapse">
  <li><a href="#average-case-analysis" id="toc-average-case-analysis" class="nav-link" data-scroll-target="#average-case-analysis">Average Case Analysis</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content column-page-left" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><strong>Spectral Graph Theory</strong></h1>
</div>



<div class="quarto-title-meta column-page-left">

    
  
    
  </div>
  


</header>


<p>The main idea of spectral graph theory is to understand graph data by constructing natural matrix representations and studying their spectrums.</p>
<p>There are many natural datasets that appear naturally as graphs:</p>
<ul>
<li><p>Social networks like Facebook and Twitter.</p></li>
<li><p>Citation networks like Google Scholar.</p></li>
<li><p>Internet graphs like the World Wide Web.</p></li>
</ul>
<p>For now, we will assume that a graph <span class="math inline">\(G=(V,E)\)</span> is undirected and unweighted on <span class="math inline">\(n\)</span> nodes.</p>
<p>There are two common matrix representations of a graph. The first is an <span class="math inline">\(n \times n\)</span> <em>adjacency</em> matrix <span class="math inline">\(\mathbf{A}\)</span> where <span class="math inline">\(A_{ij} = 1\)</span> if <span class="math inline">\((i,j) \in E\)</span> and <span class="math inline">\(A_{ij} = 0\)</span> otherwise. The second is an <span class="math inline">\(n \times n\)</span> Laplacian matrix <span class="math inline">\(\mathbf{L} = \mathbf{D} - \mathbf{A}\)</span> where <span class="math inline">\(\mathbf{D}\)</span> is the diagonal degree matrix with <span class="math inline">\(D_{ii} = \sum_{j=1}^n A_{ij}\)</span>.</p>
<p align="center">
<img src="images/laplacian.png" width="400px">
</p>
<p>It is also common to look at normalized versions of both matrices <span class="math display">\[
\bar{\mathbf{A}} = \mathbf{D}^{-1/2} \mathbf{AD}^{-1/2} \qquad
\mathbf{L} = \mathbf{I} - \bar{\mathbf{A}}.
\]</span></p>
<p>The adjacency and Laplacian matrices contain a lot of information about the graph.</p>
<ul>
<li><p>If <span class="math inline">\(\mathbf{L}\)</span> has <span class="math inline">\(k\)</span> eigenvalues equal to <span class="math inline">\(0\)</span>, then the graph <span class="math inline">\(G\)</span> has <span class="math inline">\(k\)</span> connected components.</p></li>
<li><p>The sum of cubes of the adjacency matrix’s eigenvalues is equal to the number of triangles in the graph times 6.</p></li>
<li><p>The sum of eigenvalues to the power <span class="math inline">\(q\)</span> is proportional to the number of <span class="math inline">\(q\)</span> cycles.</p></li>
</ul>
<p>Today, we’ll see how eigenvectors are useful for clustering and visualizing graphs.</p>
<p>We’ll use the edge-incidence matrix <span class="math inline">\(\mathbf{B} \in \mathbb{R}^{m \times n}\)</span> where <span class="math inline">\(m\)</span> is the number of edges in the graph. Consider the edge <span class="math inline">\((i,j) \in [m]\)</span> and the node <span class="math inline">\(k \in V\)</span>, then <span class="math display">\[
B_{(i,j),k} = \begin{cases}
1 &amp; \text{if } k = i \\
-1 &amp; \text{if } k = j \\
0 &amp; \text{otherwise}
\end{cases}.
\]</span></p>
<p>We can write the Laplacian as <span class="math display">\[
\mathbf{L} = \mathbf{B}^\top \mathbf{B}
= \mathbf{b}_1 \mathbf{b}_1^\top
+ \mathbf{b}_2 \mathbf{b}_2^\top
+ \ldots +
\mathbf{b}_m \mathbf{b}_m^\top
\]</span> where <span class="math inline">\(\mathbf{b}_i\)</span> is the <span class="math inline">\(i\)</span>th row of <span class="math inline">\(\mathbf{B}\)</span> (each row corresponds to a single edge).</p>
<p>From this view, we can conclude that</p>
<ul>
<li><p>For any vector <span class="math inline">\(\mathbf{x} \in \mathbb{R}^n\)</span>, <span class="math display">\[
\mathbf{x}^\top \mathbf{L} \mathbf{x}
= \mathbf{x}^\top \mathbf{B}^\top \mathbf{B} \mathbf{x}
= \sum_{(i,j) \in E} (x_i - x_j)^2.
\]</span></p></li>
<li><p><span class="math inline">\(\mathbf{L}\)</span> is positive semidefinite since <span class="math display">\[
\mathbf{x}^\top \mathbf{L x}
= \mathbf{x}^\top \mathbf{B}^\top \mathbf{B} \mathbf{x}
= \| \mathbf{B} \mathbf{x} \|_2^2
\geq 0
\]</span> for all <span class="math inline">\(\mathbf{x}\)</span>.</p></li>
<li><p><span class="math inline">\(\mathbf{L} = \mathbf{V \Sigma^2 V}^\top\)</span> where <span class="math inline">\(\mathbf{U \Sigma V}^\top\)</span> is the SVD of <span class="math inline">\(\mathbf{B}\)</span>. In particular, the columns of <span class="math inline">\(\mathbf{V}\)</span> are the eigenvectors of <span class="math inline">\(\mathbf{L}\)</span>.</p></li>
</ul>
<p>With these observations in mind, consider the function <span class="math inline">\(f(\mathbf{x}) = \mathbf{x}^\top \mathbf{L x}\)</span> for some vector <span class="math inline">\(\mathbf{x} \in \mathbb{R}^n\)</span>. Notice that <span class="math inline">\(f(\mathbf{x})\)</span> is small if <span class="math inline">\(\mathbf{x}\)</span> is <em>smooth</em> with respect to the graph. In terms of our linear algebraic view, if we plug a small eigenvector into <span class="math inline">\(f\)</span>, we get a small value.</p>
<p align="center">
<img src="images/smooth_graph.png" width="400px">
</p>
<p>We can formally see this connection through the the Courant-Fischer min-max principle. Let <span class="math inline">\(\mathbf{V} = [\mathbf{v}_1, \ldots, \mathbf{v}_n]\)</span> be the eigenvectors of <span class="math inline">\(\mathbf{L}\)</span> where <span class="math inline">\(\mathbf{v}_n\)</span> corresponds to the smallest eigenvalue <span class="math inline">\(\lambda_n\)</span>. Then <span class="math display">\[\begin{align*}
\mathbf{v}_n &amp;= \arg \min_{\|\mathbf{v}\|_2 =1}
\mathbf{v}^\top \mathbf{L} \mathbf{v} \\
\mathbf{v}_{n-1} &amp;= \arg \min_{\|\mathbf{v}\|_2 =1, \mathbf{v} \perp \mathbf{v}_n}
\mathbf{v}^\top \mathbf{L} \mathbf{v} \\
&amp;\vdots \\
\mathbf{v}_1 &amp;= \arg \min_{\|\mathbf{v}\|_2 =1, \mathbf{v} \perp \mathbf{v}_n, \ldots, \mathbf{v} \perp \mathbf{v}_2} \mathbf{v}^\top \mathbf{L} \mathbf{v}.
\end{align*}\]</span></p>
<p>Similarly, <span class="math display">\[\begin{align*}
\mathbf{v}_1 &amp;= \arg \max_{\|\mathbf{v}\|_2 =1} \mathbf{v}^\top \mathbf{L} \mathbf{v} \\
\mathbf{v}_{2} &amp;= \arg \max_{\|\mathbf{v}\|_2 =1, \mathbf{v} \perp \mathbf{v}_1} \mathbf{v}^\top \mathbf{L} \mathbf{v} \\
&amp;\vdots \\
\mathbf{v}_n &amp;= \arg \max_{\|\mathbf{v}\|_2 =1, \mathbf{v} \perp \mathbf{v}_1, \ldots, \mathbf{v} \perp \mathbf{v}_{n-1}} \mathbf{v}^\top \mathbf{L} \mathbf{v}.
\end{align*}\]</span></p>
<section id="spectral-clustering" class="level2">
<h2 class="anchored" data-anchor-id="spectral-clustering">Spectral Clustering</h2>
<p>We can draw another conclusion from our observation that <span class="math inline">\(\mathbf{L} = \mathbf{B}^\top \mathbf{B}\)</span>. Let <span class="math inline">\(\mathbf{c} \in \{-1, 1\}^n\)</span> be a cut indicator vector. Consider a set of vertices <span class="math inline">\(S \subseteq V\)</span>. We set <span class="math inline">\(\mathbf{c}_i = 1\)</span> if <span class="math inline">\(i \in S\)</span> and <span class="math inline">\(\mathbf{c}_i = -1\)</span> otherwise. Then <span class="math display">\[\begin{align*}
\mathbf{c}^\top \mathbf{L} \mathbf{c}
&amp;= \mathbf{c}^\top \mathbf{B}^\top \mathbf{B} \mathbf{c} \\
&amp;= \sum_{(i,j) \in E} (c_i - c_j)^2 \\
&amp;= 4 \cdot \text{cut}(S, S^c).
\end{align*}\]</span> where <span class="math inline">\(\text{cut}(S, S^c)\)</span> is the number of edges between <span class="math inline">\(S\)</span> and its complement <span class="math inline">\(S^c\)</span>.</p>
<p>Partitioning a graph is an important problem in:</p>
<ul>
<li><p>Understanding social networks,</p></li>
<li><p>Unsupervised machine learning (clustering),</p></li>
<li><p>Graph visualization, and</p></li>
<li><p>Mesh partitioning.</p></li>
</ul>
<p>We will see how this problem can be solved heuristically using the eigenvectors of the Laplacian matrix.</p>
<p>In addition, we will give an “average case” analysis of the model for a common random graph model. The tools we will use are <em>matrix concentration</em> and <em>eigenvector perturbation bounds</em>.</p>
<p>Given a graph <span class="math inline">\(G = (V,E)\)</span>, we want to partition the vertices into two sets <span class="math inline">\(S\)</span> and <span class="math inline">\(S^c\)</span> such that</p>
<ul>
<li><p>the number of edges between <span class="math inline">\(S\)</span> and <span class="math inline">\(S^c\)</span> is small and</p></li>
<li><p><span class="math inline">\(S\)</span> and <span class="math inline">\(S^c\)</span> are each not too small.</p></li>
</ul>
<p>An example of this problem is understanding community structure in social networks. In 1977, Zachary studied a karate club that split into two groups.</p>
<p>“At the beginning of the study there was an incipient conflict between the club president, John A., and Mr.&nbsp;Hi over the price of karate lessons. Mr.&nbsp;Hi, who wished to raise prices, claimed the authority to set his own lesson fees, since he was the instructor. John A., who wished to stabilize prices, claimed the authority to set the lesson fees since he was the club’s chief administrator. As time passed the entire club became divided over this issue, and the conflict became translated into ideological terms by most club members.”</p>
<p>Zachary constructed a social network by hand and used a minimum cut algorithm to correctly predict who would join each group. The <a href="https://www.jstor.org/stable/3629752">paper</a> is a classic in the field of social network analysis.</p>
<p>The problem is also generally useful for other clustering problems. Often, we can construct a synthetic graph for data that is hard to cluster.</p>
<p align="center">
<img src="images/cut_clustering.png" width="400px">
</p>
<p>Balanced cut algorithms are also used in many other applications including distributing data in graph databases, partitioning finite element meshes in scientific computing (e.g., that arise when solving differential equations), and more.</p>
<p>There are many ways to formalize the balanced cut problem.</p>
<p><strong><span class="math inline">\(\beta\)</span>-Balanced Cut:</strong> Consider <span class="math inline">\(\beta \in [0,\frac12]\)</span>. Given a graph <span class="math inline">\(G = (V,E)\)</span>, the problem is to find the set <span class="math inline">\(S \subseteq V\)</span></p>
<p><span class="math display">\[\begin{align*}
\arg \min_{S \subseteq V} \text{cut}(S, S^c) \quad \text{subject to} \quad
\min( |S|, |S^c|) \geq \beta |V|.
\end{align*}\]</span></p>
<p><strong>Sparsest Cut:</strong> Given a graph <span class="math inline">\(G = (V,E)\)</span>, the problem is to find the set <span class="math inline">\(S \subseteq V\)</span> <span class="math display">\[\begin{align*}
\arg \min_{S \subseteq V} \frac{\text{cut}(S, S^c)}{\min(|S|, |S^c|)}.
\end{align*}\]</span></p>
<p>All natural formalizations lead to NP-hard problems. There is lots of interest in designing polynomial time approximation algorithms but these tend to be slow. In practice, there are much simpler methods based on the <em>spectrum</em> of the Laplacian matrix.</p>
<p>Generally, spectral methods run in at most <span class="math inline">\(O(n^3)\)</span> time. The runtime can be further sped up if we use iterative methods for computing the eigenvectors.</p>
<p>The basic spectral clustering method is to:</p>
<ul>
<li><p>Compute the <em>second</em> smallest eigenvector <span class="math inline">\(\mathbf{v}_{n-1}\)</span> of a graph.</p></li>
<li><p>Define <span class="math inline">\(S\)</span> as the nodes with positive entries in <span class="math inline">\(\mathbf{v}_{n-1}\)</span>.</p></li>
<li><p>Return the set <span class="math inline">\(S\)</span>.</p></li>
</ul>
<p>Note that this algorithm should not make sense yet. Shortly, we will see how this method is a “relax and round” algorithm in disguise.</p>
<p>From the view of the Laplacian matrix, notice that</p>
<ul>
<li><p>the cut size is <span class="math inline">\(\mathbf{c}^\top \mathbf{L} \mathbf{c} = 4 \cdot \text{cut}(S, S^c)\)</span> and</p></li>
<li><p>the imbalance is <span class="math inline">\(|\mathbf{c}^\top \mathbf{1}|= ||S| - |S^c||\)</span>.</p></li>
</ul>
<p>We want to minimize both the cut size and the imbalance.</p>
<p>We can reach an equivalent formulation if we divide everything by <span class="math inline">\(\sqrt{n}\)</span> so that the cut indicator vector <span class="math inline">\(\mathbf{c}\)</span> has norm 1. Then <span class="math inline">\(\mathbf{c} \in \{-\frac1{\sqrt{n}}, \frac1{\sqrt{n}}\}^n\)</span> and</p>
<ul>
<li><p><span class="math inline">\(\mathbf{c}^\top \mathbf{L} \mathbf{c} = \frac{4}{n} \cdot \text{cut}(S, S^c)\)</span></p></li>
<li><p><span class="math inline">\(|\mathbf{c}^\top \mathbf{1}| = \frac{1}{\sqrt{n}} \cdot ||S| - |S^c||\)</span>.</p></li>
</ul>
<p>With this mathematical notation, the perfectly balanced cut problem is to find</p>
<p><span class="math display">\[\begin{align*}
\min_{\mathbf{c} \in \{-\frac1{\sqrt{n}}, \frac1{\sqrt{n}}\}^n}
\mathbf{c}^\top \mathbf{L} \mathbf{c} \quad \text{subject to} \quad |\mathbf{c}^\top \mathbf{1}| = 0.
\end{align*}\]</span></p>
<p>We can also write the relaxed perfectly balanced cut problem to find</p>
<p><span class="math display">\[\begin{align*}
\min_{\mathbf{c} : \|\mathbf{c}\|_2 = 1}
\mathbf{c}^\top \mathbf{L} \mathbf{c} \quad \text{subject to} \quad |\mathbf{c}^\top \mathbf{1}| = 0.
\end{align*}\]</span></p>
<p><strong>Claim:</strong> The solution to the relaxed perfectly balanced cut problem is the second smallest eigenvector <span class="math inline">\(\mathbf{v}_{n-1}\)</span> of <span class="math inline">\(\mathbf{L}\)</span>.</p>
<p><strong>Proof:</strong> By the Courant-Fischer min-max principle, the smallest eigenvector of a graph Laplacian <span class="math inline">\(\mathbf{L}\)</span> is <span class="math display">\[\begin{align*}
\mathbf{v}_n = \arg \min_{\mathbf{v}: \|\mathbf{v}\|_2 = 1} \mathbf{v}^\top \mathbf{L} \mathbf{v}
\end{align*}\]</span>. The smallest eigenvector is the constant vector <span class="math inline">\(\mathbf{1} \cdot \frac1{\sqrt{n}}\)</span>.</p>
<p>Again by the Courant-Fischer min-max principle, the second smallest eigenvector is <span class="math display">\[\begin{align*}
\mathbf{v}_{n-1} = \arg \min_{\mathbf{v}: \|\mathbf{v}\|_2 = 1, \mathbf{v}^\top \mathbf{v}_n=0} \mathbf{v}^\top \mathbf{L} \mathbf{v}.
\end{align*}\]</span> Since we know that <span class="math inline">\(\mathbf{v}_n = \mathbf{1} \cdot \frac1{\sqrt{n}}\)</span>, we know that <span class="math display">\[\begin{align*}
\mathbf{v}_{n-1} = \arg \min_{\mathbf{v}: \|\mathbf{v}\|_2 = 1, \mathbf{v}^\top \mathbf{1}=0} \mathbf{v}^\top \mathbf{L} \mathbf{v}.
\end{align*}\]</span> Notice this is exactly the relaxed perfectly balanced cut problem.</p>
<p>Our approach will be to find <span class="math inline">\(\mathbf{v}_{n-1}\)</span>. Then we will define <span class="math inline">\(S\)</span> as all the nodes with positive entries in <span class="math inline">\(\mathbf{v}_{n-1}\)</span>. Succinctly, we will set the cut indicator vector <span class="math inline">\(\mathbf{c} = \text{sign}(\mathbf{v}_{n-1})\)</span>.</p>
<p align="center">
<img src="images/cut_example.png" width="400px">
</p>
<p>There are many variants of this approach used in practice.</p>
<ul>
<li><p>Some methods perform normalization on the edge weights. For example, the Shi-Malik algorithm uses the normalized Laplacian <span class="math inline">\(\bar{\mathbf{L}} = \mathbf{I} - \mathbf{D}^{-1/2} \mathbf{A} \mathbf{D}^{-1/2}\)</span>.</p></li>
<li><p>Some methods choose different thresholds to compute the partitions.</p></li>
<li><p>Some methods split the graph into more than two partitions.</p></li>
</ul>
<p>We’ll briefly discuss multiway spectral partitioning. The approach is as follows:</p>
<ul>
<li><p>Compute the smallest <span class="math inline">\(\ell\)</span> eigenvectors <span class="math inline">\(\mathbf{v}_{n-1}, \ldots, \mathbf{v}_{n-\ell}\)</span> of <span class="math inline">\(\mathbf{L}\)</span>.</p></li>
<li><p>Represent each node by its corresponding row in the matrix <span class="math inline">\(\mathbf{V} \in \mathbb{R}^{n \times \ell}\)</span> whose columns are <span class="math inline">\(\mathbf{v}_{n-1}, \ldots, \mathbf{v}_{n-\ell}\)</span>.</p></li>
<li><p>Cluster the rows using <span class="math inline">\(k\)</span>-means clustering (or any other clustering algorithm).</p></li>
</ul>
<p>Since we used a relaxed version of the perfectly balanced cut problem, it is not clear that the algorithm will work. However, intuitively, the vectors <span class="math inline">\(\mathbf{v} \in \{\mathbf{v}_{n-1}, \ldots, \mathbf{v}_{n-\ell}\}\)</span> are smooth over the graph since <span class="math display">\[
\mathbf{v}^\top \mathbf{L} \mathbf{v} = \sum_{(i,j) \in E} (v_i - v_j)^2
\]</span> is small. The embedding explicitly encourages nodes connected by an edge to be placed in nearby locations in the embedding.</p>
<section id="average-case-analysis" class="level3">
<h3 class="anchored" data-anchor-id="average-case-analysis">Average Case Analysis</h3>
<p>So far, we showed that spectral clustering partitions a graph along a small cut between large pieces. Unfortunately, there are no formal guarantees on the quality of the partioning and it can fail for worst case input graphs.</p>
<p>We will consider a generative model that produces <em>random but realistic</em> inputs and analyze how the algorithm performs on graphs from this model. The general idea is common in algorithm design and analysis. Often, the approach is our best hope for understanding why some algorithms just work in practice. For example, linear regression is motivated by “average case” Bayesian modeling.</p>
<p>We will consider the stochastic block model (SBM) which is a random graph model that is commonly used to model social networks.</p>
<p><strong>Stochastic Block Model:</strong> Let <span class="math inline">\(0&lt;q &lt; p &lt; 1\)</span>. We will call <span class="math inline">\(G_n(p,q)\)</span> a distribution over graphs on <span class="math inline">\(n\)</span> nodes. Each graph is split equally into two blocks <span class="math inline">\(B\)</span> and <span class="math inline">\(C\)</span> each with <span class="math inline">\(\frac{n}{2}\)</span> nodes. Any two nodes in the <em>same group</em> are connected with probability <span class="math inline">\(p\)</span> (including self-loops) and any two nodes in <em>different groups</em> are connected with probability <span class="math inline">\(q\)</span>.</p>
<p>Consider the adjacency matrix <span class="math inline">\(\mathbf{A}\)</span> of a graph <span class="math inline">\(G_n(p,q)\)</span>.</p>
<p align="center">
<img src="images/stochastic_block_model.png" width="400px">
</p>
<p>Note that we ordered the nodes in the adjacency matrix given in the figure. In reality, the order of the nodes would be “scrambled” and the blocks would not be so obvious.</p>
<p>Given a graph drawn from the stochastic block model <span class="math inline">\(G_n(p,q)\)</span>, our goal is to find the ground truth balanced partitions <span class="math inline">\(B\)</span> and <span class="math inline">\(C\)</span> using spectral clustering. Our first step is to understand the second smallest eigenvector of the Laplacian <span class="math inline">\(\mathbf{L} = \mathbf{D} - \mathbf{A}\)</span>. We will start by considering the <em>expected matrices</em> <span class="math inline">\(\mathbb{E}[\mathbf{L}] = \mathbb{E}[\mathbf{D}] - \mathbb{E}[\mathbf{A}]\)</span>.</p>
<p align="center">
<img src="images/expected_stochastic_block_model.png" width="400px">
</p>
<p>We will use the simplicity of the expected adjacency matrix to understand the eigenvectors of the expected Laplacian matrix. The top eigenvector <span class="math inline">\(\mathbf{v}_1\)</span> is proportional to the vector <span class="math inline">\(\mathbf{1}\)</span> with the eigenvalue <span class="math inline">\(\lambda_1 = \frac{(p+q)n}{2}\)</span>. The second eigenvector <span class="math inline">\(\mathbf{v}_2\)</span> is the cut indicator for groups <span class="math inline">\(B\)</span> and <span class="math inline">\(C\)</span> with eigenvalue <span class="math inline">\(\lambda_2 = \frac{(p-q)n}{2}\)</span>. We can check that the eigendecomposition is correct because there are only two eigenvectors.</p>
<p align="center">
<img src="images/expected_adjacency.png" width="400px">
</p>
<p>Notice that if we correctly compute the second eigenvector <span class="math inline">\(\mathbf{v}_2\)</span>, then we can exactly recover the ground truth partition <span class="math inline">\(B\)</span> and <span class="math inline">\(C\)</span>.</p>
<p>Because <span class="math inline">\(\mathbb{E}[\mathbf{L}] = \mathbb{E}[\mathbf{D}] - \mathbb{E}[\mathbf{A}]\)</span>, the second smallest eigenvector of <span class="math inline">\(\mathbb{E}[\mathbf{L}]\)</span> is the second largest eigenvector of <span class="math inline">\(\mathbb{E}[\mathbf{A}]\)</span>. So we know that the cut indicator vector <span class="math inline">\(\mathbf{c}\)</span> is the second smallest eigenvector of <span class="math inline">\(\mathbb{E}[\mathbf{L}]\)</span>.</p>
<p>If the random graph <span class="math inline">\(G\)</span> drawn from the stochastic block model <span class="math inline">\(G_n(p,q)\)</span> were exactly equal to its expectation, we could recover the ground truth partition <span class="math inline">\(B\)</span> and <span class="math inline">\(C\)</span>. However, the graph <span class="math inline">\(G\)</span> is not exactly equal to its expectation because of the randomness in the generative process.</p>
<p>Nonetheless, we will use matrix concentration to show that the eigenvectors of <span class="math inline">\(\mathbf{L}\)</span> are close to the eigenvectors of <span class="math inline">\(\mathbb{E}[\mathbf{L}]\)</span>. The approach is analagous to scalar concentration inequalities that we’ve seen before like Markov’s, Chebyshev’s, and Chernoff’s inequalities.</p>
<p><strong><a href="https://link.springer.com/content/pdf/10.1007/BF02785860.pdf">Matrix Concentration Inequality</a>:</strong> If <span class="math inline">\(p \geq O \left( \frac{\log^4 n}{n} \right)\)</span>, then with high probability <span class="math display">\[\begin{align*}
\| \mathbf{A} - \mathbb{E}[ \mathbf{A} ] \|_2 \leq O \left( \sqrt{pn} \right)
\end{align*}\]</span> where <span class="math inline">\(\| \cdot \|_2\)</span> is the matrix spectral norm.</p>
<p>Recall that the spectral norm of a matrix <span class="math inline">\(\mathbf{A}\)</span> is <span class="math display">\[
\| \mathbf{A} \|_2 = \max_{\mathbf{x} :\|\mathbf{x}\|_2=1 } \| \mathbf{A} \mathbf{x} \|_2 = \sigma_1(\mathbf{A})
\]</span> where <span class="math inline">\(\sigma_1(\mathbf{A})\)</span> is the largest singular value of <span class="math inline">\(\mathbf{A}\)</span>.</p>
<p>When the graph is drawn from the stochastic block model, we know that the constant vector of the adjacency matrix is roughly the top eigenvector (because the smallest eigenvector of the Laplacian is roughly the constant vector). Then we know that spectral norm of the adjacency matrix <span class="math inline">\(\| \mathbf{A} \|_2\)</span> is on the order of <span class="math inline">\(O(p \sqrt{n})\)</span> so another way of thinking about the right hand side of the matrix concentration inequality is <span class="math inline">\(\| \mathbf{A}\|_2/\sqrt{p}\)</span>. In other words, the bound tightens as <span class="math inline">\(p\)</span> increases.</p>
<p>For the stochastic block model application, we want to show that the second eigenvectors of <span class="math inline">\(\mathbf{A}\)</span> and <span class="math inline">\(\mathbb{E}[\mathbf{A}]\)</span> are close. For this, we will use the following theorem.</p>
<p><strong>Davis-Kahan Eigenvector Perturbation Theorem:</strong> Suppose <span class="math inline">\(\mathbf{A}, \bar{\mathbf{A}} \in \mathbb{R}^{n \times n}\)</span> are symmetric matrices with eigenvectors <span class="math inline">\(\mathbf{v}_1, \ldots, \mathbf{v}_n\)</span> and <span class="math inline">\(\bar{\mathbf{v}}_1, \ldots, \bar{\mathbf{v}}_n\)</span>, respectively. Let <span class="math inline">\(\theta(\mathbf{v}, \bar{\mathbf{v}})\)</span> denote the angle between two vectors <span class="math inline">\(\mathbf{v}\)</span> and <span class="math inline">\(\bar{\mathbf{v}}\)</span>. Then <span class="math display">\[\begin{align*}
\sin \theta(\mathbf{v}_i, \bar{\mathbf{v}}_i)
\leq \frac{\| \mathbf{A} - \bar{\mathbf{A}} \|_2 }{\min_{j \neq i} |\lambda_i - \lambda_j|}
\end{align*}\]</span> where <span class="math inline">\(\lambda_1 \geq \ldots \geq \lambda_n\)</span> and are the eigenvalues of <span class="math inline">\(\bar{\mathbf{A}}\)</span>.</p>
<p>We can exhibit a matrix where the bound is tight. Let <span class="math inline">\(\mathbf{A}\)</span> and <span class="math inline">\(\bar{\mathbf{A}}\)</span> be the matrices in the figure below. The top eigenvector <span class="math inline">\(\mathbf{v}_1\)</span> is <span class="math inline">\([1,0]\)</span> whereas the top eigenvector <span class="math inline">\(\bar{\mathbf{v}}_1\)</span> is <span class="math inline">\([0,1]\)</span>. The angle between these two vectors is <span class="math inline">\(\frac{\pi}{2}\)</span> so <span class="math inline">\(\sin(\theta(\mathbf{v}_1, \bar{\mathbf{v}}_1)) = 1\)</span>. Since <span class="math inline">\(\lambda_1 = 1+\epsilon\)</span> and <span class="math inline">\(\lambda_2 = 1\)</span>, the bound gives <span class="math inline">\(\frac{\epsilon}{\epsilon} = 1\)</span>.</p>
<p align="center">
<img src="images/matrix_perturbation.png" width="400px">
</p>
<p>We will apply the Davis-Kahan theorem to the stochastic block model with <span class="math inline">\(\bar{\mathbf{A}} = \mathbb{E}[\mathbf{A}]\)</span>.</p>
<p>Recall that <span class="math inline">\(\mathbb{E}[\mathbf{A}]\)</span> has eigenvalues <span class="math inline">\(\lambda_1 = \frac{n(p+q)}{2}\)</span> and <span class="math inline">\(\lambda_2 = \frac{n(p-q)}{2}\)</span>. Then <span class="math inline">\(\min_{j \neq i} |\lambda_i - \lambda_j| = \min( qn, \frac{n(p-q)}{2})\)</span>. Assume that <span class="math inline">\(\frac{n(p-q)}{2}\)</span> is the minimum of these two gaps.</p>
<p>Then applying the matrix concentration inequality and the Davis-Kahan theorem, we get the following.</p>
<p>For <span class="math inline">\(p \geq O \left( \frac{\log^4 n}{n} \right)\)</span>, with high probability we have <span class="math display">\[\begin{align*}
\sin \theta(\mathbf{v}_2, \bar{\mathbf{v}}_2)
&amp;\leq \frac{O \left( \sqrt{pn} \right)}{\min_{j \neq i} |\lambda_i - \lambda_j|} \\
&amp;\leq \frac{O \left( \sqrt{pn} \right)}{\frac{n(p-q)}{2}} \\
&amp;= O \left( \frac{\sqrt{p}}{(p-q)\sqrt{n}} \right).
\end{align*}\]</span></p>
<p>To relate the angle to the <span class="math inline">\(\ell_2\)</span>-norm difference, consider two unit vectors <span class="math inline">\(\mathbf{a}\)</span> and <span class="math inline">\(\mathbf{b}\)</span>. We have <span class="math display">\[\begin{align*}
\| \mathbf{a - b} \|_2^2
&amp;= \| \mathbf{a} \|_2^2 + \| \mathbf{b} \|_2^2 - 2 \mathbf{a}^\top \mathbf{b} \\
&amp;= 2 - 2 \cos(\theta) \\
&amp;= 2 - 2 \sqrt{1-\sin^2(\theta)} \\
&amp;\leq 2 - 2 (1-\sin^2(\theta) \\
&amp; = 2 \sin^2(\theta)
\end{align*}\]</span> where the inequality follows since <span class="math inline">\(\sin^2(\theta) \leq 1\)</span>. Then <span class="math display">\[\begin{align*}
\| \mathbf{v}_2 - \bar{\mathbf{v}}_2 \|_2^2 \leq
O \left( \frac{p}{(p-q)^2 n} \right).
\end{align*}\]</span></p>
<p>We know that <span class="math inline">\(\bar{\mathbf{v}}_2\)</span> is <span class="math inline">\(\frac1{\sqrt{n}} \cdot \mathbf{c}\)</span> where <span class="math inline">\(\mathbf{c}\)</span> is the cut indicator vector for the ground truth partition <span class="math inline">\(B\)</span> and <span class="math inline">\(C\)</span>.</p>
<p>We want to show that <span class="math inline">\(\text{sign}(\mathbf{v}_2)\)</span> is close to <span class="math inline">\(\mathbf{v}_2\)</span>. Notice they will only differ at locations where <span class="math inline">\(\mathbf{v}_2\)</span> and <span class="math inline">\(\bar{\mathbf{v}}_2\)</span> have opposite signs. Since every entry <span class="math inline">\(i\)</span> that differs in sign contributes at least <span class="math inline">\(\frac1{n}\)</span> to the squared <span class="math inline">\(\ell_2\)</span> norm of <span class="math inline">\(\mathbf{v}_2 - \bar{\mathbf{v}}_2\)</span>, we know that <span class="math inline">\(\mathbf{v}_2\)</span> and <span class="math inline">\(\bar{\mathbf{v}}_2\)</span> differ in at most <span class="math inline">\(O \left( \frac{p}{(p-q)^2} \right)\)</span> entries.</p>
<p><strong>Average Case Result:</strong> If <span class="math inline">\(G\)</span> is a stochastic block model graph with <span class="math inline">\(p \geq O \left( \frac{\log^4 n}{n} \right)\)</span>. Then if we compute the second largest eigenvector <span class="math inline">\(\mathbf{v}_2\)</span> of <span class="math inline">\(\mathbf{A}\)</span> and assign nodes to the communities according to the sign pattern of this vector, we will correctly assign all but <span class="math inline">\(O \left( \frac{p}{(p-q)^2} \right)\)</span> nodes.</p>
<p>Notice that the error is small when <span class="math inline">\(p\)</span> is large and <span class="math inline">\(q\)</span> is small. The problem becomes more challenging when <span class="math inline">\(p \approx q\)</span>. In this setting, the Davis-Kahan theorem becomes loose <em>and</em> it is more difficult to tell the difference between the two groups.</p>



</section>
</section>

</main> <!-- /main -->
<script>
document.addEventListener("DOMContentLoaded", function () {
  const wordsPerMinute = 200;
  const text = document.body.innerText;
  const words = text.trim().split(/\s+/).length;
  const readingTime = Math.ceil(words / wordsPerMinute);

  const readTimeEl = document.createElement("div");
  readTimeEl.innerText = `⏱️ ${readingTime} min read`;

  // Style it to appear centered
  readTimeEl.style.fontSize = "0.9em";
  readTimeEl.style.margin = "1em auto";
  readTimeEl.style.textAlign = "left";
  readTimeEl.style.width = "100%";

  const title = document.querySelector("h1");
  if (title) {
    title.parentNode.insertBefore(readTimeEl, title.nextSibling);
  }
});
</script>
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>